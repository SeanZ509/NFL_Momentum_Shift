{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanz\\AppData\\Local\\Temp\\ipykernel_16512\\3598231924.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['field_goal_result'].fillna('none', inplace=True)\n",
      "C:\\Users\\seanz\\AppData\\Local\\Temp\\ipykernel_16512\\3598231924.py:519: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '548.7808836884615' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  dfV5.at[index, 'Home_Momentum_Score'] = dfV5.at[index - 1, 'Home_Momentum_Score'] + home_momentum_gain\n",
      "C:\\Users\\seanz\\AppData\\Local\\Temp\\ipykernel_16512\\3598231924.py:520: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '489.3937295340633' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  dfV5.at[index, 'Away_Momentum_Score'] = dfV5.at[index - 1, 'Away_Momentum_Score'] + away_momentum_gain\n",
      "C:\\Users\\seanz\\AppData\\Local\\Temp\\ipykernel_16512\\3598231924.py:573: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  dfV5 = dfV5.groupby('game_id', group_keys=False).apply(detect_momentum_shifts)\n",
      "C:\\Users\\seanz\\AppData\\Local\\Temp\\ipykernel_16512\\3598231924.py:581: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dfV5[columns_to_fill] = dfV5[columns_to_fill].fillna(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>PC14</th>\n",
       "      <th>PC15</th>\n",
       "      <th>PC16</th>\n",
       "      <th>PC17</th>\n",
       "      <th>PC18</th>\n",
       "      <th>PC19</th>\n",
       "      <th>PC20</th>\n",
       "      <th>PC21</th>\n",
       "      <th>PC22</th>\n",
       "      <th>PC23</th>\n",
       "      <th>PC24</th>\n",
       "      <th>PC25</th>\n",
       "      <th>PC26</th>\n",
       "      <th>PC27</th>\n",
       "      <th>PC28</th>\n",
       "      <th>PC29</th>\n",
       "      <th>PC30</th>\n",
       "      <th>Momentum_Shift_Occurred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.502194</td>\n",
       "      <td>-3.218508</td>\n",
       "      <td>-0.044483</td>\n",
       "      <td>-0.692268</td>\n",
       "      <td>0.207728</td>\n",
       "      <td>0.617730</td>\n",
       "      <td>-0.095790</td>\n",
       "      <td>-0.244981</td>\n",
       "      <td>0.253502</td>\n",
       "      <td>-0.905387</td>\n",
       "      <td>-1.129721</td>\n",
       "      <td>0.761692</td>\n",
       "      <td>-0.316661</td>\n",
       "      <td>0.775689</td>\n",
       "      <td>0.529774</td>\n",
       "      <td>0.099472</td>\n",
       "      <td>2.245678</td>\n",
       "      <td>0.057101</td>\n",
       "      <td>-0.596545</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.106489</td>\n",
       "      <td>0.182943</td>\n",
       "      <td>0.267666</td>\n",
       "      <td>-0.104805</td>\n",
       "      <td>0.543723</td>\n",
       "      <td>-0.244041</td>\n",
       "      <td>-0.033606</td>\n",
       "      <td>0.612715</td>\n",
       "      <td>0.095361</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.428102</td>\n",
       "      <td>-3.246133</td>\n",
       "      <td>0.211228</td>\n",
       "      <td>-0.427948</td>\n",
       "      <td>0.206565</td>\n",
       "      <td>0.619298</td>\n",
       "      <td>0.392401</td>\n",
       "      <td>-0.273335</td>\n",
       "      <td>-0.108111</td>\n",
       "      <td>-0.083365</td>\n",
       "      <td>-0.978670</td>\n",
       "      <td>0.892659</td>\n",
       "      <td>-0.029448</td>\n",
       "      <td>-0.045745</td>\n",
       "      <td>0.487501</td>\n",
       "      <td>0.066728</td>\n",
       "      <td>-0.285052</td>\n",
       "      <td>0.317987</td>\n",
       "      <td>-0.058645</td>\n",
       "      <td>-0.122947</td>\n",
       "      <td>0.307805</td>\n",
       "      <td>-0.098938</td>\n",
       "      <td>0.218983</td>\n",
       "      <td>0.119934</td>\n",
       "      <td>-0.352395</td>\n",
       "      <td>0.675005</td>\n",
       "      <td>-0.245362</td>\n",
       "      <td>-0.029322</td>\n",
       "      <td>0.568054</td>\n",
       "      <td>0.084004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.196172</td>\n",
       "      <td>-3.057688</td>\n",
       "      <td>1.820782</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>0.171288</td>\n",
       "      <td>0.602331</td>\n",
       "      <td>0.510450</td>\n",
       "      <td>-0.785140</td>\n",
       "      <td>-0.151083</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>-0.968615</td>\n",
       "      <td>0.976115</td>\n",
       "      <td>-0.060222</td>\n",
       "      <td>-0.286907</td>\n",
       "      <td>0.489112</td>\n",
       "      <td>-0.026622</td>\n",
       "      <td>-0.186035</td>\n",
       "      <td>0.236064</td>\n",
       "      <td>0.102568</td>\n",
       "      <td>-0.559631</td>\n",
       "      <td>1.016895</td>\n",
       "      <td>0.141309</td>\n",
       "      <td>0.302030</td>\n",
       "      <td>0.146483</td>\n",
       "      <td>-0.556321</td>\n",
       "      <td>0.652954</td>\n",
       "      <td>-0.219550</td>\n",
       "      <td>-0.090924</td>\n",
       "      <td>-0.206692</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.521493</td>\n",
       "      <td>-2.918547</td>\n",
       "      <td>4.443888</td>\n",
       "      <td>1.935242</td>\n",
       "      <td>0.949298</td>\n",
       "      <td>0.537175</td>\n",
       "      <td>2.031028</td>\n",
       "      <td>0.302749</td>\n",
       "      <td>0.057638</td>\n",
       "      <td>0.453378</td>\n",
       "      <td>-0.444415</td>\n",
       "      <td>1.154558</td>\n",
       "      <td>-0.003316</td>\n",
       "      <td>-0.032604</td>\n",
       "      <td>0.331423</td>\n",
       "      <td>-0.483051</td>\n",
       "      <td>-0.276693</td>\n",
       "      <td>-0.191189</td>\n",
       "      <td>-0.417322</td>\n",
       "      <td>-2.645951</td>\n",
       "      <td>-0.819220</td>\n",
       "      <td>0.260691</td>\n",
       "      <td>-0.118316</td>\n",
       "      <td>-0.071153</td>\n",
       "      <td>-0.277915</td>\n",
       "      <td>0.423098</td>\n",
       "      <td>-0.209122</td>\n",
       "      <td>-0.245814</td>\n",
       "      <td>-1.100681</td>\n",
       "      <td>-0.606992</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.170653</td>\n",
       "      <td>-3.158175</td>\n",
       "      <td>-0.832833</td>\n",
       "      <td>-0.398895</td>\n",
       "      <td>-0.329927</td>\n",
       "      <td>0.098929</td>\n",
       "      <td>-1.306571</td>\n",
       "      <td>0.874564</td>\n",
       "      <td>-1.304541</td>\n",
       "      <td>3.139035</td>\n",
       "      <td>0.899681</td>\n",
       "      <td>0.905133</td>\n",
       "      <td>-2.938221</td>\n",
       "      <td>0.742369</td>\n",
       "      <td>0.451527</td>\n",
       "      <td>-0.209335</td>\n",
       "      <td>1.523188</td>\n",
       "      <td>-0.790911</td>\n",
       "      <td>3.285815</td>\n",
       "      <td>-1.212305</td>\n",
       "      <td>0.865374</td>\n",
       "      <td>-1.474200</td>\n",
       "      <td>0.939521</td>\n",
       "      <td>-0.462161</td>\n",
       "      <td>-0.172800</td>\n",
       "      <td>1.062859</td>\n",
       "      <td>0.305143</td>\n",
       "      <td>-0.017631</td>\n",
       "      <td>1.443531</td>\n",
       "      <td>-0.090435</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0 -2.502194 -3.218508 -0.044483 -0.692268  0.207728  0.617730 -0.095790   \n",
       "1 -2.428102 -3.246133  0.211228 -0.427948  0.206565  0.619298  0.392401   \n",
       "2 -2.196172 -3.057688  1.820782  0.013693  0.171288  0.602331  0.510450   \n",
       "3 -1.521493 -2.918547  4.443888  1.935242  0.949298  0.537175  2.031028   \n",
       "4 -2.170653 -3.158175 -0.832833 -0.398895 -0.329927  0.098929 -1.306571   \n",
       "\n",
       "        PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
       "0 -0.244981  0.253502 -0.905387 -1.129721  0.761692 -0.316661  0.775689   \n",
       "1 -0.273335 -0.108111 -0.083365 -0.978670  0.892659 -0.029448 -0.045745   \n",
       "2 -0.785140 -0.151083  0.007881 -0.968615  0.976115 -0.060222 -0.286907   \n",
       "3  0.302749  0.057638  0.453378 -0.444415  1.154558 -0.003316 -0.032604   \n",
       "4  0.874564 -1.304541  3.139035  0.899681  0.905133 -2.938221  0.742369   \n",
       "\n",
       "       PC15      PC16      PC17      PC18      PC19      PC20      PC21  \\\n",
       "0  0.529774  0.099472  2.245678  0.057101 -0.596545  0.007475  0.006780   \n",
       "1  0.487501  0.066728 -0.285052  0.317987 -0.058645 -0.122947  0.307805   \n",
       "2  0.489112 -0.026622 -0.186035  0.236064  0.102568 -0.559631  1.016895   \n",
       "3  0.331423 -0.483051 -0.276693 -0.191189 -0.417322 -2.645951 -0.819220   \n",
       "4  0.451527 -0.209335  1.523188 -0.790911  3.285815 -1.212305  0.865374   \n",
       "\n",
       "       PC22      PC23      PC24      PC25      PC26      PC27      PC28  \\\n",
       "0  0.106489  0.182943  0.267666 -0.104805  0.543723 -0.244041 -0.033606   \n",
       "1 -0.098938  0.218983  0.119934 -0.352395  0.675005 -0.245362 -0.029322   \n",
       "2  0.141309  0.302030  0.146483 -0.556321  0.652954 -0.219550 -0.090924   \n",
       "3  0.260691 -0.118316 -0.071153 -0.277915  0.423098 -0.209122 -0.245814   \n",
       "4 -1.474200  0.939521 -0.462161 -0.172800  1.062859  0.305143 -0.017631   \n",
       "\n",
       "       PC29      PC30  Momentum_Shift_Occurred  \n",
       "0  0.612715  0.095361                    False  \n",
       "1  0.568054  0.084004                    False  \n",
       "2 -0.206692  0.003514                    False  \n",
       "3 -1.100681 -0.606992                    False  \n",
       "4  1.443531 -0.090435                    False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv('NFL_pbp_2009-2019.csv', low_memory=False)\n",
    "\n",
    "threshold = 100000\n",
    "df['field_goal_result'].fillna('none', inplace=True)\n",
    "dfV2 = df.loc[:, df.isnull().sum() < threshold]\n",
    "missing_values = dfV2.isnull().sum()\n",
    "\n",
    "statistical_cols = ['play_id', 'game_id', 'home_team', 'away_team', 'posteam', \n",
    "                    'defteam', 'side_of_field', 'yardline_100', 'half_seconds_remaining', \n",
    "                    'game_seconds_remaining', 'game_half', 'drive', 'qtr', 'down', 'goal_to_go', 'time', \n",
    "                    'yrdln', 'ydstogo', 'ydsnet', 'desc', 'play_type', 'yards_gained', 'home_timeouts_remaining', \n",
    "                    'away_timeouts_remaining', 'total_home_score',  'total_away_score', 'score_differential', 'home_wp', 'away_wp', 'ep']\n",
    "\n",
    "game_dynamics_cols = [\n",
    "    'punt_blocked', 'first_down_rush', 'first_down_pass', 'first_down_penalty', 'third_down_converted',\n",
    "    'third_down_failed', 'fourth_down_converted', 'fourth_down_failed', 'incomplete_pass', 'interception',\n",
    "    'fumble_forced', 'fumble_not_forced', 'fumble_out_of_bounds', 'solo_tackle', 'safety', 'penalty',\n",
    "    'tackled_for_loss', 'fumble_lost', 'own_kickoff_recovery', 'own_kickoff_recovery_td', 'qb_hit',\n",
    "    'rush_attempt', 'pass_attempt', 'sack', 'touchdown', 'pass_touchdown', 'rush_touchdown', 'field_goal_result',\n",
    "    'return_touchdown', 'extra_point_attempt', 'two_point_attempt', 'field_goal_attempt', 'kickoff_attempt',\n",
    "    'punt_attempt', 'fumble', 'complete_pass', 'shotgun', 'no_huddle', 'punt_inside_twenty', 'kickoff_inside_twenty']\n",
    "\n",
    "columns_to_keep = statistical_cols + game_dynamics_cols\n",
    "dfV3 = dfV2[columns_to_keep]\n",
    "\n",
    "dfV4 = dfV3.drop(['play_id', 'game_seconds_remaining', 'fumble_forced'], axis=1)\n",
    "dfV4 = dfV4.dropna(subset=['down', 'defteam', 'posteam'])\n",
    "dfV4 = dfV4.reset_index(drop=True)\n",
    "\n",
    "# Indicators for if within last 2 minutes of the half and the whole game\n",
    "dfV4['close_to_end_of_half'] = (dfV4['half_seconds_remaining'] <= 120).astype(int)\n",
    "dfV4['close_to_end_of_game'] = ((dfV4['half_seconds_remaining'] <= 120) & (dfV4['game_half'] == 'Half2')).astype(int)\n",
    "\n",
    "# Indicator for if the touchdown was for the away or home team\n",
    "dfV4['home_td'] = ((dfV4['touchdown'] == 1) & (dfV4['posteam'] != dfV4['away_team'])).astype(int)\n",
    "dfV4['away_td'] = ((dfV4['touchdown'] == 1) & (dfV4['posteam'] != dfV4['home_team'])).astype(int)\n",
    "\n",
    "# Trackers for the difference in both teams' win probability after each play\n",
    "dfV4['home_wp_change'] = dfV4['home_wp'].diff().fillna(0)\n",
    "dfV4['away_wp_change'] = dfV4['away_wp'].diff().fillna(0)\n",
    "\n",
    "# Indicator for turnover\n",
    "dfV4['turnover'] = (\n",
    "    (dfV4['safety'] == 1) |\n",
    "    (dfV4['interception'] == 1) |\n",
    "    (dfV4['fumble_lost'] == 1) |\n",
    "    ((dfV4['fourth_down_converted'] == 0) & (dfV4['down'] == 4))\n",
    ").astype(int)\n",
    "\n",
    "# Drive time - Added drive ended indicator to help - Manually resets after end of game, half, and change of possession\n",
    "dfV4['drive_ended'] = (\n",
    "    (dfV4['posteam'] != dfV4['posteam'].shift(1)) |  \n",
    "    (dfV4['game_id'] != dfV4['game_id'].shift(1)) |  \n",
    "    dfV4['desc'].str.contains('END GAME', na=False) |  \n",
    "    dfV4['desc'].str.contains('END QUARTER', na=False)  \n",
    ").astype(int)\n",
    "dfV4['drive'] = (\n",
    "    (dfV4['posteam'].ne(dfV4['posteam'].shift())) |\n",
    "    (dfV4['game_id'].ne(dfV4['game_id'].shift()))\n",
    ").cumsum()\n",
    "dfV4['drive_time_seconds'] = (\n",
    "    dfV4.groupby(['game_id', 'drive'])['half_seconds_remaining']\n",
    "    .transform('first') - dfV4['half_seconds_remaining']\n",
    ")\n",
    "dfV4['drive_time_seconds'] = dfV4.apply(\n",
    "    lambda row: 0 if row['drive_ended'] == 1 else row['drive_time_seconds'], axis=1\n",
    ")\n",
    "dfV4['drive_time_seconds'] = dfV4.groupby(['game_id', 'drive'])['drive_time_seconds'].cumsum()\n",
    "\n",
    "# Indicator for long touchdowns\n",
    "dfV4['long_td'] = ((dfV4['touchdown'] == 1) & (dfV4['yards_gained'] >= 50)).astype(int)\n",
    "\n",
    "# Trackers for score differentials and lead changes\n",
    "dfV4['home_score_differential'] = dfV4['total_home_score'] - dfV4['total_away_score']\n",
    "dfV4['away_score_differential'] = -dfV4['home_score_differential']\n",
    "dfV4['lead_change'] = ((dfV4['home_score_differential'].diff() < 0) &\n",
    "                       (dfV4['home_score_differential'].shift() * dfV4['home_score_differential'] < 0)).astype(int)\n",
    "\n",
    "# Combining first down indicators\n",
    "dfV4['first_down'] = ((dfV4['first_down_pass'] == 1) | (dfV4['first_down_rush'] == 1) | (dfV4['first_down_penalty'] == 1)).astype(int)\n",
    "\n",
    "# Indicators for scoring drives - Removing\n",
    "dfV4['home_scoring_drive'] = (\n",
    "    (dfV4['home_td'] == 1) \n",
    ").astype(int)\n",
    "dfV4['away_scoring_drive'] = (\n",
    "    (dfV4['away_td'] == 1) \n",
    ").astype(int)\n",
    "\n",
    "# Helper for consecutive scoring events - Remove Later!!!!!!!!!!!!!!\n",
    "dfV4['home_scoring_events'] = (\n",
    "    (dfV4['posteam'] != dfV4['away_team']) & \n",
    "    ((dfV4['home_td'] == 1) | (dfV4['field_goal_result'] == 'made'))\n",
    ").astype(int)\n",
    "dfV4['away_scoring_events'] = (\n",
    "    (dfV4['posteam'] != dfV4['home_team']) & \n",
    "    ((dfV4['away_td'] == 1) | (dfV4['field_goal_result'] == 'made'))\n",
    ").astype(int)\n",
    "\n",
    "# Consecutive Scoring Events + Helper function \n",
    "def calc_consecutive_cumsum_with_game_reset(series, reset_series, game_ids):\n",
    "    cumsum = 0\n",
    "    consecutive = []\n",
    "    prev_game_id = None  \n",
    "    \n",
    "    for i in range(len(series)):\n",
    "        if game_ids[i] != prev_game_id:\n",
    "            cumsum = 0 \n",
    "        if reset_series[i] == 1:  \n",
    "            cumsum = 0\n",
    "        if series[i] == 1:  \n",
    "            cumsum += 1\n",
    "        consecutive.append(cumsum)\n",
    "        prev_game_id = game_ids[i]  \n",
    "    return consecutive\n",
    "\n",
    "dfV4['home_csum_scores'] = calc_consecutive_cumsum_with_game_reset(\n",
    "    dfV4['home_scoring_events'], dfV4['away_scoring_events'], dfV4['game_id']\n",
    ")\n",
    "dfV4['away_csum_scores'] = calc_consecutive_cumsum_with_game_reset(\n",
    "    dfV4['away_scoring_events'], dfV4['home_scoring_events'], dfV4['game_id']\n",
    ")\n",
    "\n",
    "#Consecutive defensive stops\n",
    "dfV4['home_def_stop'] = (\n",
    "    (dfV4['posteam'] != dfV4['home_team']) &  ((dfV4['punt_attempt'] == 1) |  (dfV4['turnover'] == 1)) & \n",
    "    ~dfV4['field_goal_result'].isin(['made'])  \n",
    ").astype(int)\n",
    "dfV4['away_def_stop'] = (\n",
    "    (dfV4['posteam'] != dfV4['away_team']) & ((dfV4['punt_attempt'] == 1) |  (dfV4['turnover'] == 1)) & \n",
    "    ~dfV4['field_goal_result'].isin(['made'])\n",
    ").astype(int)\n",
    "\n",
    "def calc_consecutive_defensive_stops_with_game_reset(series, reset_series, game_ids):\n",
    "    cumsum = 0\n",
    "    consecutive = []\n",
    "    prev_game_id = None  \n",
    "    for i in range(len(series)):\n",
    "        if game_ids[i] != prev_game_id:\n",
    "            cumsum = 0\n",
    "        if reset_series[i] == 1:\n",
    "            cumsum = 0\n",
    "        if series[i] == 1:\n",
    "            cumsum += 1\n",
    "        consecutive.append(cumsum)\n",
    "        prev_game_id = game_ids[i]  \n",
    "    return consecutive\n",
    "\n",
    "dfV4['home_csum_def_stops'] = calc_consecutive_defensive_stops_with_game_reset(\n",
    "    dfV4['home_def_stop'], dfV4['away_scoring_events'], dfV4['game_id']\n",
    ")\n",
    "dfV4['away_csum_def_stops'] = calc_consecutive_defensive_stops_with_game_reset(\n",
    "    dfV4['away_def_stop'], dfV4['home_scoring_events'], dfV4['game_id']\n",
    ")\n",
    "\n",
    "# Home/Away Drive Numbers\n",
    "dfV4['away_drive_number'] = (\n",
    "    dfV4.loc[dfV4['posteam'] != dfV4['home_team']]\n",
    "    .groupby('game_id')['drive_ended'].cumsum()\n",
    ")\n",
    "dfV4['home_drive_number'] = (\n",
    "    dfV4.loc[dfV4['posteam'] == dfV4['home_team']]\n",
    "    .groupby('game_id')['drive_ended'].cumsum()\n",
    ")\n",
    "\n",
    "# Offense needs to score\n",
    "dfV4['off_need_score'] = (\n",
    "    (dfV4['down'].isin([3, 4])) & \n",
    "    (abs(dfV4['score_differential']) <= 8) & \n",
    "    (dfV4['qtr'] >= 4) &\n",
    "    (dfV4['first_down'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Defense Needs a Stop\n",
    "dfV4['def_need_stop'] = (\n",
    "    (dfV4['down'].isin([3, 4])) & \n",
    "    (abs(dfV4['score_differential']) <= 8) & \n",
    "    (dfV4['qtr'] >= 4) &\n",
    "    (dfV4['turnover'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Drought Ending score\n",
    "dfV4['drought_end_play'] = (\n",
    "    ((dfV4['away_csum_scores'].shift(1) >= 2) & (dfV4['away_csum_scores'] == 0) & (dfV4['home_scoring_events'] == 1)) |\n",
    "    ((dfV4['home_csum_scores'].shift(1) >= 2) & (dfV4['home_csum_scores'] == 0) & (dfV4['away_scoring_events'] == 1))\n",
    ").astype(int)\n",
    "\n",
    "# Defensive touchdown\n",
    "dfV4['def_td'] = (\n",
    "    ((dfV4['fumble'] == 1) & (dfV4['return_touchdown'] == 1)) |\n",
    "    ((dfV4['interception'] == 1) & (dfV4['return_touchdown'] == 1))\n",
    ").astype(int)\n",
    "\n",
    "# Defensive touchdown\n",
    "dfV4['off_td'] = (\n",
    "    (dfV4['pass_touchdown'] == 1) | (dfV4['rush_touchdown'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Special Teams touchdown\n",
    "dfV4['st_return_td'] = (\n",
    "    ((dfV4['kickoff_attempt'] == 1) & (dfV4['return_touchdown'] == 1)) | \n",
    "    ((dfV4['punt_attempt'] == 1) & (dfV4['return_touchdown'] == 1))  \n",
    ").astype(int)\n",
    "\n",
    "# Big special teams play...punt blocked, field goal blocked, return_touchdown, kick recovery, pin team near endzone\n",
    "dfV4['big_st_play'] = (\n",
    "    (dfV4['punt_blocked'] == 1) | \n",
    "    (dfV4['field_goal_result'] == 'blocked') | \n",
    "    (dfV4['own_kickoff_recovery'] == 1) | \n",
    "    (dfV4['st_return_td'] == 1) | \n",
    "    (dfV4['kickoff_inside_twenty'] == 1) | \n",
    "    (dfV4['punt_inside_twenty'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Scoring type differentiatior, touchdowns should hold more weight than a field goal, other types may hold more weight also\n",
    "dfV4['scoring_type'] = np.select(\n",
    "    [\n",
    "        dfV4['field_goal_result'] == 'made',\n",
    "        dfV4['off_td'] == 1,\n",
    "        dfV4['def_td'] == 1,\n",
    "        dfV4['st_return_td'] == 1,\n",
    "    ],\n",
    "    ['fg', 'off_td', 'def_td', 'st_td'],\n",
    "    default='none'\n",
    ")\n",
    "\n",
    "# Indicator for big offensive play\n",
    "dfV4['big_offensive_play'] = (\n",
    "        (dfV4['yards_gained'] >= 40) |\n",
    "        (dfV4['long_td'] == 1) |\n",
    "        ((dfV4['off_need_score'] == 1) & (dfV4['off_td'] == 1))\n",
    ").astype(int)\n",
    "\n",
    "# Indicator for big defensive play\n",
    "dfV4['big_defensive_play'] = (\n",
    "    (dfV4['sack'] == 1) |\n",
    "    (dfV4['tackled_for_loss'] == 1) |\n",
    "    ((dfV4['def_need_stop'] == 1) & ((dfV4['def_td'] == 'def_td')) | dfV4['turnover'] == 1) |\n",
    "    (dfV4['scoring_type'] == 'def_td')\n",
    ").astype(int)\n",
    "\n",
    "#Quick Score and Quick Stop #### Needs fixing, only want 1 on last play of drive when they score or get stop, right now 1 for whole drive\n",
    "dfV4['total_drive_time'] = dfV4.groupby('drive')['drive_time_seconds'].transform('last') \n",
    "dfV4['cumulative_drive_time'] = dfV4.groupby(['game_id', 'drive'])['drive_time_seconds'].cumsum()\n",
    "dfV4['long_drive_triggered'] = (\n",
    "    dfV4.groupby(['game_id', 'drive'])['cumulative_drive_time']\n",
    "    .transform(lambda x: (x > 360).idxmax() == x.index)  # Flags the first row that exceeds 360s\n",
    ").astype(int)\n",
    "\n",
    "dfV4['quick_score'] = (\n",
    "    (dfV4['drive_time_seconds'] < 180) &\n",
    "    ((dfV4['touchdown'] == 1) | (dfV4['field_goal_result'] == 'made')) &\n",
    "    (dfV4.groupby('drive')['drive_time_seconds'].transform('last') == dfV4['drive_time_seconds'])\n",
    ").astype(int)\n",
    "dfV4['quick_stop'] = (\n",
    "    (dfV4['total_drive_time'] < 180) & \n",
    "    (dfV4['scoring_type'] == 'none') &\n",
    "    (dfV4.groupby('drive')['drive_time_seconds'].transform('last') == dfV4['drive_time_seconds'])\n",
    ").astype(int)\n",
    "\n",
    "# Consecutive first downs\n",
    "dfV4['home_csum_first_downs'] = 0\n",
    "dfV4['away_csum_first_downs'] = 0\n",
    "dfV4['home_csum_first_downs'] = (\n",
    "    dfV4.groupby(['home_team', 'away_team', 'home_drive_number'])['first_down']\n",
    "    .cumsum()\n",
    "    .where(dfV4['posteam'] != 'away_team', 0)\n",
    ")\n",
    "dfV4['away_csum_first_downs'] = (\n",
    "    dfV4.groupby(['home_team', 'away_team', 'away_drive_number'])['first_down']\n",
    "    .cumsum()\n",
    "    .where(dfV4['posteam'] != 'home_team', 0)\n",
    ")\n",
    "\n",
    "\n",
    "columns_to_remove = [\n",
    "    'ep', 'punt_blocked', 'first_down_rush', 'first_down_pass', \n",
    "    'third_down_converted', 'third_down_failed', 'fourth_down_converted', \n",
    "    'fourth_down_failed', 'incomplete_pass', 'interception', 'fumble_not_forced', \n",
    "    'fumble_out_of_bounds', 'solo_tackle', 'safety', 'penalty', 'tackled_for_loss', \n",
    "    'fumble_lost', 'own_kickoff_recovery', 'own_kickoff_recovery_td', 'qb_hit', \n",
    "    'rush_attempt', 'pass_attempt', 'sack', 'extra_point_attempt', 'two_point_attempt', \n",
    "    'field_goal_attempt', 'kickoff_attempt', 'punt_attempt', 'fumble', 'pass_touchdown', 'rush_touchdown'\n",
    "    'complete_pass', 'shotgun', 'home_scoring_drive', 'away_scoring_drive','home_scoring_events','away_scoring_events',\n",
    "    'rush_touchdown', 'field_goal_result', 'return_touchdown', 'complete_pass', 'no_huddle', 'punt_inside_twenty', 'kickoff_inside_twenty',\n",
    "    'time', 'yrdln', 'ydstogo', 'ydsnet', 'desc', 'side_of_field', 'yardline_100', 'desc', 'drive', 'game_half', 'drive_ended', 'drive_time_seconds',\n",
    "    'touchdown', 'score_differential', 'total_drive_time'\n",
    "]\n",
    "\n",
    "dfV5 = dfV4.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "dynamics = [\n",
    "    ('big_offensive_play', dfV5['big_offensive_play'] == 1),\n",
    "    ('big_defensive_play', dfV5['big_defensive_play'] == 1),\n",
    "    ('off_td', dfV5['off_td'] == 1),\n",
    "    ('def_td', dfV5['def_td'] == 1),\n",
    "    ('big_st_play', dfV5['big_st_play'] == 1),\n",
    "    ('st_return_td', dfV5['st_return_td'] == 1),\n",
    "    ('off_need_score', dfV5['off_need_score'] == 1),\n",
    "    ('def_need_stop', dfV5['def_need_stop'] == 1),\n",
    "    ('drought_end_play', dfV5['drought_end_play'] == 1),\n",
    "    ('home_csum_scores', dfV5['home_csum_scores'] >= 2),\n",
    "    ('away_csum_scores', dfV5['away_csum_scores'] >= 2),\n",
    "    ('home_csum_def_stops', dfV5['home_csum_def_stops'] >= 2),\n",
    "    ('away_csum_def_stops', dfV5['away_csum_def_stops'] >= 2),\n",
    "    ('home_csum_first_downs', dfV5['home_csum_first_downs'] >= 2),\n",
    "    ('away_csum_first_downs', dfV5['away_csum_first_downs'] >= 2),\n",
    "    ('long_td', dfV5['long_td'] == 1),\n",
    "    ('quick_score', dfV5['quick_score'] == 1),\n",
    "    ('quick_stop', dfV5['quick_stop'] == 1),\n",
    "    ('home_score_differential', dfV5['home_score_differential'] == 1),\n",
    "    ('away_score_differential', dfV5['away_score_differential'] == 1),\n",
    "]\n",
    "\n",
    "\n",
    "def_wp_change = {\n",
    "    \"big_defensive_play\": 0.029471,\n",
    "    \"def_td\": 0.016322,\n",
    "    \"big_st_play\": 0.034637,\n",
    "    \"st_return_td\": 0.040082,\n",
    "    \"def_need_stop\": 0.042132,\n",
    "    \"quick_stop\": 0.029971\n",
    "}\n",
    "\n",
    "off_wp_change = {\n",
    "    \"big_offensive_play\": 0.038602,\n",
    "    \"off_td\": 0.028432,\n",
    "    \"off_need_score\":  0.035536, \n",
    "    \"drought_end_play\": 0.028891,\n",
    "    \"long_td\": 0.033325,\n",
    "    \"quick_score\": 0.026664\n",
    "}\n",
    "\n",
    "streaks_multipliers = {\n",
    "    \"home_csum_scores\": 1.118986,\n",
    "    \"away_csum_scores\": 1.118986,\n",
    "    \"home_csum_first_downs\": 1.1112094,\n",
    "    \"away_csum_first_downs\": 1.1112094,\n",
    "    \"home_csum_def_stops\": 1.111932,\n",
    "    \"away_csum_def_stops\": 1.111932,\n",
    "}\n",
    "\n",
    "score_game_multipliers = {\n",
    "    \"tied_or_1_score\": 1.06634844,\n",
    "    \"2_score\": 1.035777727,\n",
    "    \"3_or_more_score\": 1.0274060\n",
    "}\n",
    "\n",
    "qtr_multipliers = {\n",
    "    \"first_and_fourth\": 1.5522285,\n",
    "    \"second_and_third\": 1.3201836\n",
    "}\n",
    "\n",
    "home_away_multipliers = {\n",
    "    \"home\": 1.07949869,  \n",
    "    \"away\": 1.06027507 \n",
    "}\n",
    "\n",
    "boost_case_multipliers = {\n",
    "    \"home_and_4th\": 1.122276683,  \n",
    "    \"away_and_1st\": 1.16675933,  \n",
    "    \"none\": 1.0           \n",
    "}\n",
    "\n",
    "decay_multipliers = {\n",
    "    \"opponent_scores\": 0.68004571,\n",
    "    \"turnover\": 0.21742678,\n",
    "    \"opponent_ends_drought\": 0.18212307,\n",
    "    \"long_possession\":  0.1534018395,\n",
    "    \"none\": 0.0  \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def calculate_multipliers(row, index, category, is_offensive):\n",
    "    if abs(row['home_score_differential']) <= 8:\n",
    "        S = score_game_multipliers[\"tied_or_1_score\"]\n",
    "    elif 9 <= abs(row['home_score_differential']) <= 16:\n",
    "        S = score_game_multipliers[\"2_score\"]\n",
    "    else:\n",
    "        S = score_game_multipliers[\"3_or_more_score\"]\n",
    "\n",
    "    team = row['posteam'] if is_offensive else row['defteam']\n",
    "    HA = home_away_multipliers.get(team, 1.0)\n",
    "\n",
    "    if row['qtr'] == 1 or row['qtr'] == 4:\n",
    "        Q = qtr_multipliers[\"first_and_fourth\"]\n",
    "    else:\n",
    "        Q = qtr_multipliers[\"second_and_third\"]\n",
    "\n",
    "    if is_offensive:\n",
    "        if row['posteam'] == 'home' and row['qtr'] == 4:\n",
    "            B = boost_case_multipliers[\"home_and_4th\"]\n",
    "        elif row['posteam'] == 'away' and row['qtr'] == 1:\n",
    "            B = boost_case_multipliers[\"away_and_1st\"]\n",
    "        else:\n",
    "            B = 1.0\n",
    "    else:\n",
    "        if team == 'home' and row['qtr'] == 4:\n",
    "            B = boost_case_multipliers[\"home_and_4th\"]\n",
    "        elif team == 'away' and row['qtr'] == 1:\n",
    "            B = boost_case_multipliers[\"away_and_1st\"]\n",
    "        else:\n",
    "            B = 1.0\n",
    "\n",
    "    CS = 1.0\n",
    "   \n",
    "    if is_offensive:\n",
    "        if row['posteam'] == row['home_team']:\n",
    "            if row['home_csum_scores'] >= 2:\n",
    "                if row['home_csum_scores'] > dfV5.at[index - 1, 'home_csum_scores']: \n",
    "                    CS = streaks_multipliers['home_csum_scores']\n",
    "            elif row['home_csum_first_downs'] >= 4:\n",
    "                if row['home_csum_first_downs'] > dfV5.at[index - 1, 'home_csum_first_downs']: \n",
    "                    CS = streaks_multipliers['home_csum_first_downs']\n",
    "            else:\n",
    "                CS = 1.0\n",
    "        else:\n",
    "            if row['away_csum_scores'] >= 2:\n",
    "                if row['away_csum_scores'] > dfV5.at[index - 1, 'away_csum_scores']: \n",
    "                    CS = streaks_multipliers['away_csum_scores']\n",
    "            elif row['away_csum_first_downs'] >= 4:\n",
    "                if row['away_csum_first_downs'] >  dfV5.at[index - 1, 'away_csum_first_downs']: \n",
    "                    CS = streaks_multipliers['away_csum_first_downs']\n",
    "            else:\n",
    "                CS = 1.0\n",
    "    else:\n",
    "        if row['defteam'] == row['home_team']:\n",
    "            if row['home_csum_def_stops'] >= 2:\n",
    "                if row['home_csum_def_stops'] > dfV5.at[index - 1, 'home_csum_def_stops']: \n",
    "                    CS = streaks_multipliers['home_csum_def_stops']\n",
    "            else:\n",
    "                CS = 1.0\n",
    "        else:\n",
    "            if row['away_csum_def_stops'] >= 2:\n",
    "                if row['away_csum_def_stops'] > dfV5.at[index - 1, 'away_csum_def_stops']:\n",
    "                    CS = streaks_multipliers['away_csum_def_stops']\n",
    "            else:\n",
    "                CS = 1.0\n",
    "\n",
    "    return S, HA, B, CS, Q\n",
    "\n",
    "\n",
    "\n",
    "def calculate_momentum_gain(wp_change_value, S, HA, CS, B, Q):\n",
    "    return wp_change_value * (S * HA * CS * B * Q) * 1000\n",
    "\n",
    "\n",
    "\n",
    "def calculate_decay(row, category, momentum_gain):\n",
    "    if category in ['off_td', 'long_td', 'def_td', 'st_return_td']:\n",
    "        D = decay_multipliers['opponent_scores']\n",
    "    elif row['turnover'] == 1:\n",
    "        D = decay_multipliers['turnover']\n",
    "    elif row['drought_end_play'] == 1:\n",
    "        D = decay_multipliers[\"opponent_ends_drought\"]\n",
    "    elif row['long_drive_triggered'] == 1:  \n",
    "        D = decay_multipliers['long_possession']\n",
    "    else:\n",
    "        D = decay_multipliers['none']\n",
    "\n",
    "    return momentum_gain * D\n",
    "\n",
    "\n",
    "\n",
    "def update_momentum_scores(dfV5):\n",
    "    dfV5['Home_Momentum_Score'] = 500\n",
    "    dfV5['Away_Momentum_Score'] = 500\n",
    "\n",
    "    dfV5['game_id_diff'] = dfV5['game_id'] != dfV5['game_id'].shift(1)\n",
    "\n",
    "    for index, row in dfV5.iterrows():\n",
    "        if index == 0:  \n",
    "            continue\n",
    "\n",
    "        if row['game_id_diff']:\n",
    "            dfV5.at[index, 'Home_Momentum_Score'] = 500\n",
    "            dfV5.at[index, 'Away_Momentum_Score'] = 500\n",
    "            continue\n",
    "\n",
    "        home_momentum_gain = 0\n",
    "        away_momentum_gain = 0\n",
    "\n",
    "        for category, wp_change_value in off_wp_change.items():\n",
    "            if row[category] == 1:\n",
    "                S, HA, B, CS, Q = calculate_multipliers(row, index, category, True)\n",
    "                momentum_gain = calculate_momentum_gain(wp_change_value, S, HA, CS, B, Q)\n",
    "                momentum_loss = calculate_decay(row, category, momentum_gain)\n",
    "\n",
    "                if row['posteam'] == row['home_team']:\n",
    "                    home_momentum_gain += momentum_gain\n",
    "                    away_momentum_gain -= momentum_loss\n",
    "                else:\n",
    "                    away_momentum_gain += momentum_gain\n",
    "                    home_momentum_gain -= momentum_loss\n",
    "\n",
    "        for category, wp_change_value in def_wp_change.items():\n",
    "            if row[category] == 1:\n",
    "                S, HA, B, CS, Q = calculate_multipliers(row, index, category, False)\n",
    "                momentum_gain = calculate_momentum_gain(wp_change_value, S, HA, CS, B, Q)\n",
    "                momentum_loss = calculate_decay(row, category, momentum_gain)\n",
    "\n",
    "                if row['defteam'] == row['home_team']:\n",
    "                    home_momentum_gain += momentum_gain\n",
    "                    away_momentum_gain -= momentum_loss\n",
    "                else:\n",
    "                    away_momentum_gain += momentum_gain\n",
    "                    home_momentum_gain -= momentum_loss\n",
    "\n",
    "        dfV5.at[index, 'Home_Momentum_Score'] = dfV5.at[index - 1, 'Home_Momentum_Score'] + home_momentum_gain\n",
    "        dfV5.at[index, 'Away_Momentum_Score'] = dfV5.at[index - 1, 'Away_Momentum_Score'] + away_momentum_gain\n",
    "\n",
    "update_momentum_scores(dfV5)\n",
    "\n",
    "dfV5['Game_Momentum_Diff'] = 0\n",
    "\n",
    "historical_max_diff_mean = dfV5.groupby('game_id')['Game_Momentum_Diff'].max().mean()\n",
    "historical_max_diff_std = dfV5.groupby('game_id')['Game_Momentum_Diff'].max().std()\n",
    "\n",
    "base_threshold = historical_max_diff_mean + 0.8 * historical_max_diff_std #.7\n",
    "\n",
    "dfV5['Game_Momentum_Diff'] = abs(dfV5['Home_Momentum_Score'] - dfV5['Away_Momentum_Score'])\n",
    "dfV5['Dynamic_Threshold'] = None\n",
    "dfV5['Momentum_Holding_Team'] = None\n",
    "\n",
    "def detect_momentum_shifts(game_data):\n",
    "    momentum_holding_team = None\n",
    "    last_shift_home_momentum = game_data.iloc[0]['Home_Momentum_Score']\n",
    "    last_shift_away_momentum = game_data.iloc[0]['Away_Momentum_Score']\n",
    "    max_momentum_diff_so_far = 0\n",
    "\n",
    "    for i in range(1, len(game_data)): \n",
    "        if i < 10:  # Ignore shifts for the first 10 plays\n",
    "            continue\n",
    "        home_momentum_diff = game_data.iloc[i]['Home_Momentum_Score'] - last_shift_home_momentum\n",
    "        away_momentum_diff = game_data.iloc[i]['Away_Momentum_Score'] - last_shift_away_momentum        \n",
    "\n",
    "        current_momentum_diff = abs(game_data.iloc[i]['Home_Momentum_Score'] - game_data.iloc[i]['Away_Momentum_Score'])\n",
    "        max_momentum_diff_so_far = max(max_momentum_diff_so_far, current_momentum_diff)\n",
    "        game_threshold = max(base_threshold, 0.8 * max_momentum_diff_so_far) #.7\n",
    "        game_data.iloc[i, game_data.columns.get_loc('Dynamic_Threshold')] = game_threshold\n",
    "\n",
    "        home_momentum_shift = False\n",
    "        away_momentum_shift = False\n",
    "\n",
    "        if home_momentum_diff >= game_threshold and away_momentum_diff < game_threshold * 0.8: #.5\n",
    "            home_momentum_shift = True\n",
    "        elif away_momentum_diff >= game_threshold and home_momentum_diff < game_threshold * 0.8: #.5\n",
    "            away_momentum_shift = True\n",
    "\n",
    "        if home_momentum_shift:\n",
    "            momentum_holding_team = \"Home\"\n",
    "            last_shift_home_momentum = game_data.iloc[i]['Home_Momentum_Score']\n",
    "            last_shift_away_momentum = game_data.iloc[i]['Away_Momentum_Score']\n",
    "        elif away_momentum_shift:\n",
    "            momentum_holding_team = \"Away\"\n",
    "            last_shift_home_momentum = game_data.iloc[i]['Home_Momentum_Score']\n",
    "            last_shift_away_momentum = game_data.iloc[i]['Away_Momentum_Score']\n",
    "\n",
    "        game_data.iloc[i, game_data.columns.get_loc('Momentum_Holding_Team')] = momentum_holding_team\n",
    "\n",
    "    return game_data\n",
    "\n",
    "dfV5 = dfV5.groupby('game_id', group_keys=False).apply(detect_momentum_shifts)\n",
    "\n",
    "dfV5['Momentum_Shift_Occurred'] = dfV5.groupby('game_id')['Momentum_Holding_Team'].transform(\n",
    "    lambda x: x.ne(x.shift()) & x.notna()\n",
    ")\n",
    "\n",
    "columns_to_fill = ['home_drive_number', 'away_drive_number', 'home_csum_first_downs', \n",
    "                    'away_csum_first_downs', 'Dynamic_Threshold', 'yards_gained']\n",
    "dfV5[columns_to_fill] = dfV5[columns_to_fill].fillna(0)\n",
    "\n",
    "features = dfV5.drop(['Momentum_Shift_Occurred'], axis=1)  \n",
    "numeric_df = dfV5.select_dtypes(include=[np.number])\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(numeric_df)\n",
    "\n",
    "pca = PCA(n_components=0.90)\n",
    "principal_components = pca.fit_transform(scaled_data)\n",
    "\n",
    "pca_df = pd.DataFrame(principal_components, columns=[f'PC{i+1}' for i in range(pca.n_components_)])\n",
    "pca_df['Momentum_Shift_Occurred'] = dfV5['Momentum_Shift_Occurred'].values\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Selected Features Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9794\n",
      "Test Accuracy:  0.9794\n",
      "=== Training Set Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    331300\n",
      "           1       0.00      0.00      0.00      6975\n",
      "\n",
      "    accuracy                           0.98    338275\n",
      "   macro avg       0.49      0.50      0.49    338275\n",
      "weighted avg       0.96      0.98      0.97    338275\n",
      "\n",
      "=== Test Set Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     82061\n",
      "           1       0.00      0.00      0.00      1726\n",
      "\n",
      "    accuracy                           0.98     83787\n",
      "   macro avg       0.49      0.50      0.49     83787\n",
      "weighted avg       0.96      0.98      0.97     83787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "df = dfV5.copy()\n",
    "\n",
    "selected_features = [\n",
    "    'total_home_score',\n",
    "    'total_away_score',\n",
    "    'home_wp_change',\n",
    "    'away_wp_change',\n",
    "    'Home_Momentum_Score',\n",
    "    'Away_Momentum_Score'\n",
    "]\n",
    "\n",
    "target_col = 'Momentum_Shift_Occurred'\n",
    "unique_games = df['game_id'].unique()\n",
    "\n",
    "unique_games_sorted = sorted(unique_games)\n",
    "train_size = int(0.8 * len(unique_games_sorted))\n",
    "\n",
    "train_games = unique_games_sorted[:train_size]\n",
    "test_games = unique_games_sorted[train_size:]\n",
    "train_df = df[df['game_id'].isin(train_games)].copy()\n",
    "test_df = df[df['game_id'].isin(test_games)].copy()\n",
    "\n",
    "X_train = train_df[selected_features].values\n",
    "y_train = train_df[target_col].values.astype(int)\n",
    "X_test = test_df[selected_features].values\n",
    "y_test = test_df[target_col].values.astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(16, 16),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred = mlp.predict(X_train_scaled)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# 2) Predict on test set\n",
    "y_test_pred = mlp.predict(X_test_scaled)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc:.4f}\")\n",
    "\n",
    "print(\"=== Training Set Report ===\")\n",
    "print(classification_report(y_train, y_train_pred, zero_division=0))\n",
    "\n",
    "# Test set report\n",
    "print(\"=== Test Set Report ===\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Threshold Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9827\n",
      "Test Accuracy:  0.9789\n",
      "=== Train Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    331300\n",
      "           1       0.72      0.26      0.39      6975\n",
      "\n",
      "    accuracy                           0.98    338275\n",
      "   macro avg       0.85      0.63      0.69    338275\n",
      "weighted avg       0.98      0.98      0.98    338275\n",
      "\n",
      "=== Test Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     82061\n",
      "           1       0.47      0.16      0.24      1726\n",
      "\n",
      "    accuracy                           0.98     83787\n",
      "   macro avg       0.72      0.58      0.61     83787\n",
      "weighted avg       0.97      0.98      0.97     83787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "excluded_cols = ['game_id', 'Momentum_Shift_Occurred', 'Momentum_Holding_Team']\n",
    "target_col = 'Momentum_Shift_Occurred'\n",
    "feature_df = df.drop(columns=excluded_cols, errors='ignore')\n",
    "\n",
    "numeric_cols = feature_df.select_dtypes(include=['number']).columns\n",
    "categorical_cols = feature_df.select_dtypes(exclude=['number']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    feature_df = pd.get_dummies(feature_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "unique_games = df['game_id'].unique()\n",
    "unique_games_sorted = sorted(unique_games)\n",
    "train_size = int(0.8 * len(unique_games_sorted))\n",
    "train_games = unique_games_sorted[:train_size]\n",
    "test_games = unique_games_sorted[train_size:]\n",
    "\n",
    "feature_df['game_id'] = df['game_id']\n",
    "train_features = feature_df[feature_df['game_id'].isin(train_games)].drop(columns='game_id')\n",
    "test_features = feature_df[feature_df['game_id'].isin(test_games)].drop(columns='game_id')\n",
    "X_train = train_features.values\n",
    "X_test = test_features.values\n",
    "y_train = df.loc[df['game_id'].isin(train_games), target_col].astype(int).values\n",
    "y_test = df.loc[df['game_id'].isin(test_games), target_col].astype(int).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16, 16), activation='relu', solver='adam', max_iter=200, random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred = mlp.predict(X_train_scaled)\n",
    "y_test_pred = mlp.predict(X_test_scaled)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc:.4f}\")\n",
    "print(\"=== Train Report ===\")\n",
    "print(classification_report(y_train, y_train_pred, zero_division=0))\n",
    "print(\"=== Test Report ===\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Threshold Hyper Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best Params: {'alpha': 0.01, 'hidden_layer_sizes': (32, 16), 'solver': 'adam'}\n",
      "Best CV Score: 0.26859078911338263\n",
      "\n",
      "=== Training Set ===\n",
      "Accuracy: 0.9831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    331300\n",
      "           1       0.75      0.27      0.40      6975\n",
      "\n",
      "    accuracy                           0.98    338275\n",
      "   macro avg       0.87      0.64      0.70    338275\n",
      "weighted avg       0.98      0.98      0.98    338275\n",
      "\n",
      "\n",
      "=== Test Set ===\n",
      "Accuracy: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     82061\n",
      "           1       0.46      0.15      0.23      1726\n",
      "\n",
      "    accuracy                           0.98     83787\n",
      "   macro avg       0.72      0.57      0.61     83787\n",
      "weighted avg       0.97      0.98      0.97     83787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "\n",
    "excluded_cols = ['game_id', 'Momentum_Shift_Occurred', 'Momentum_Holding_Team']\n",
    "target_col = 'Momentum_Shift_Occurred'\n",
    "feature_df = df.drop(columns=excluded_cols, errors='ignore')\n",
    "\n",
    "numeric_cols = feature_df.select_dtypes(include=['number']).columns\n",
    "categorical_cols = feature_df.select_dtypes(exclude=['number']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    feature_df = pd.get_dummies(feature_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "unique_games = df['game_id'].unique()\n",
    "unique_games_sorted = sorted(unique_games)\n",
    "train_size = int(0.8 * len(unique_games_sorted))\n",
    "train_games = unique_games_sorted[:train_size]\n",
    "test_games = unique_games_sorted[train_size:]\n",
    "\n",
    "feature_df['game_id'] = df['game_id']\n",
    "train_df = feature_df[feature_df['game_id'].isin(train_games)].drop(columns='game_id')\n",
    "test_df = feature_df[feature_df['game_id'].isin(test_games)].drop(columns='game_id')\n",
    "\n",
    "X_train = train_df.values\n",
    "y_train = df.loc[df['game_id'].isin(train_games), target_col].astype(int).values\n",
    "X_test = test_df.values\n",
    "y_test = df.loc[df['game_id'].isin(test_games), target_col].astype(int).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "groups_train = df.loc[df['game_id'].isin(train_games), 'game_id'].values\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "mlp_base = MLPClassifier(max_iter=200, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(16,16), (32,16), (32,32,16)],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'solver': ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=mlp_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',           \n",
    "    cv=group_kfold,       \n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train, groups=groups_train)\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "print(\"Best CV Score:\", grid_search.best_score_)\n",
    "\n",
    "best_mlp = grid_search.best_estimator_\n",
    "\n",
    "best_mlp.fit(X_train_scaled, y_train)\n",
    "y_train_pred = best_mlp.predict(X_train_scaled)\n",
    "y_test_pred = best_mlp.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n=== Training Set ===\")\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Accuracy: {train_acc:.4f}\")\n",
    "print(classification_report(y_train, y_train_pred, zero_division=0))\n",
    "\n",
    "print(\"\\n=== Test Set ===\")\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Accuracy: {test_acc:.4f}\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold = 0.17, Best F1 (Test) = 0.353\n",
      "\n",
      "=== Training Set Results at Best Threshold ===\n",
      "Precision: 0.381\n",
      "Recall:    0.660\n",
      "F1:        0.483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99    331300\n",
      "           1       0.38      0.66      0.48      6975\n",
      "\n",
      "    accuracy                           0.97    338275\n",
      "   macro avg       0.69      0.82      0.73    338275\n",
      "weighted avg       0.98      0.97      0.97    338275\n",
      "\n",
      "\n",
      "=== Test Set Results at Best Threshold ===\n",
      "Precision: 0.281\n",
      "Recall:    0.473\n",
      "F1:        0.353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     82061\n",
      "           1       0.28      0.47      0.35      1726\n",
      "\n",
      "    accuracy                           0.96     83787\n",
      "   macro avg       0.63      0.72      0.67     83787\n",
      "weighted avg       0.97      0.96      0.97     83787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "y_train_proba = mlp.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_proba = mlp.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0.0\n",
    "\n",
    "for t in [x / 100 for x in range(101)]:\n",
    "    y_test_pred_custom = (y_test_proba >= t).astype(int)\n",
    "    f1 = f1_score(y_test, y_test_pred_custom, zero_division=0)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"Best threshold = {best_threshold:.2f}, Best F1 (Test) = {best_f1:.3f}\")\n",
    "\n",
    "y_train_pred_optimal = (y_train_proba >= best_threshold).astype(int)\n",
    "train_precision = precision_score(y_train, y_train_pred_optimal, zero_division=0)\n",
    "train_recall = recall_score(y_train, y_train_pred_optimal, zero_division=0)\n",
    "train_f1 = f1_score(y_train, y_train_pred_optimal, zero_division=0)\n",
    "\n",
    "print(\"\\n=== Training Set Results at Best Threshold ===\")\n",
    "print(f\"Precision: {train_precision:.3f}\")\n",
    "print(f\"Recall:    {train_recall:.3f}\")\n",
    "print(f\"F1:        {train_f1:.3f}\")\n",
    "print(classification_report(y_train, y_train_pred_optimal, zero_division=0))\n",
    "\n",
    "y_test_pred_optimal = (y_test_proba >= best_threshold).astype(int)\n",
    "test_precision = precision_score(y_test, y_test_pred_optimal, zero_division=0)\n",
    "test_recall = recall_score(y_test, y_test_pred_optimal, zero_division=0)\n",
    "test_f1 = f1_score(y_test, y_test_pred_optimal, zero_division=0)\n",
    "\n",
    "print(\"\\n=== Test Set Results at Best Threshold ===\")\n",
    "print(f\"Precision: {test_precision:.3f}\")\n",
    "print(f\"Recall:    {test_recall:.3f}\")\n",
    "print(f\"F1:        {test_f1:.3f}\")\n",
    "print(classification_report(y_test, y_test_pred_optimal, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold + Hyper Tuning Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best Params: {'alpha': 0.01, 'hidden_layer_sizes': (32, 16), 'solver': 'adam'}\n",
      "Best CV Score (F1): 0.26859078911338263\n",
      "\n",
      "=== Default Threshold (0.5) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     82061\n",
      "           1       0.46      0.15      0.23      1726\n",
      "\n",
      "    accuracy                           0.98     83787\n",
      "   macro avg       0.72      0.57      0.61     83787\n",
      "weighted avg       0.97      0.98      0.97     83787\n",
      "\n",
      "\n",
      "=== Threshold Tuning ===\n",
      "Best threshold = 0.16, Best F1 (Test) = 0.362\n",
      "\n",
      "=== Train Set at Best Threshold ===\n",
      "Precision: 0.395\n",
      "Recall:    0.714\n",
      "F1:        0.509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99    331300\n",
      "           1       0.40      0.71      0.51      6975\n",
      "\n",
      "    accuracy                           0.97    338275\n",
      "   macro avg       0.69      0.85      0.75    338275\n",
      "weighted avg       0.98      0.97      0.98    338275\n",
      "\n",
      "\n",
      "=== Test Set at Best Threshold ===\n",
      "Precision: 0.286\n",
      "Recall:    0.493\n",
      "F1:        0.362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     82061\n",
      "           1       0.29      0.49      0.36      1726\n",
      "\n",
      "    accuracy                           0.96     83787\n",
      "   macro avg       0.64      0.73      0.67     83787\n",
      "weighted avg       0.97      0.96      0.97     83787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "excluded_cols = ['game_id', 'Momentum_Shift_Occurred', 'Momentum_Holding_Team']\n",
    "target_col = 'Momentum_Shift_Occurred'\n",
    "feature_df = df.drop(columns=excluded_cols, errors='ignore')\n",
    "\n",
    "numeric_cols = feature_df.select_dtypes(include=['number']).columns\n",
    "categorical_cols = feature_df.select_dtypes(exclude=['number']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    feature_df = pd.get_dummies(feature_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "unique_games = df['game_id'].unique()\n",
    "unique_games_sorted = sorted(unique_games)\n",
    "train_size = int(0.8 * len(unique_games_sorted))\n",
    "train_games = unique_games_sorted[:train_size]\n",
    "test_games = unique_games_sorted[train_size:]\n",
    "\n",
    "feature_df['game_id'] = df['game_id']\n",
    "train_df = feature_df[feature_df['game_id'].isin(train_games)].drop(columns='game_id')\n",
    "test_df = feature_df[feature_df['game_id'].isin(test_games)].drop(columns='game_id')\n",
    "\n",
    "X_train = train_df.values\n",
    "y_train = df.loc[df['game_id'].isin(train_games), target_col].astype(int).values\n",
    "X_test = test_df.values\n",
    "y_test = df.loc[df['game_id'].isin(test_games), target_col].astype(int).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "groups_train = df.loc[df['game_id'].isin(train_games), 'game_id'].values\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "mlp_base = MLPClassifier(max_iter=200, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(16,16), (32,16), (32,32,16)],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'solver': ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=mlp_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',  \n",
    "    cv=group_kfold,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train, groups=groups_train)\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "print(\"Best CV Score (F1):\", grid_search.best_score_)\n",
    "\n",
    "best_mlp = grid_search.best_estimator_\n",
    "best_mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\n=== Default Threshold (0.5) ===\")\n",
    "y_test_pred_default = best_mlp.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_test_pred_default, zero_division=0))\n",
    "\n",
    "print(\"\\n=== Threshold Tuning ===\")\n",
    "y_train_proba = best_mlp.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_proba = best_mlp.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0.0\n",
    "\n",
    "for t in [x / 100 for x in range(101)]:\n",
    "    y_test_pred_custom = (y_test_proba >= t).astype(int)\n",
    "    f1_val = f1_score(y_test, y_test_pred_custom, zero_division=0)\n",
    "    if f1_val > best_f1:\n",
    "        best_f1 = f1_val\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"Best threshold = {best_threshold:.2f}, Best F1 (Test) = {best_f1:.3f}\")\n",
    "\n",
    "y_train_pred_optimal = (y_train_proba >= best_threshold).astype(int)\n",
    "train_precision = precision_score(y_train, y_train_pred_optimal, zero_division=0)\n",
    "train_recall = recall_score(y_train, y_train_pred_optimal, zero_division=0)\n",
    "train_f1 = f1_score(y_train, y_train_pred_optimal, zero_division=0)\n",
    "\n",
    "print(\"\\n=== Train Set at Best Threshold ===\")\n",
    "print(f\"Precision: {train_precision:.3f}\")\n",
    "print(f\"Recall:    {train_recall:.3f}\")\n",
    "print(f\"F1:        {train_f1:.3f}\")\n",
    "print(classification_report(y_train, y_train_pred_optimal, zero_division=0))\n",
    "\n",
    "y_test_pred_optimal = (y_test_proba >= best_threshold).astype(int)\n",
    "test_precision = precision_score(y_test, y_test_pred_optimal, zero_division=0)\n",
    "test_recall = recall_score(y_test, y_test_pred_optimal, zero_division=0)\n",
    "test_f1 = f1_score(y_test, y_test_pred_optimal, zero_division=0)\n",
    "\n",
    "print(\"\\n=== Test Set at Best Threshold ===\")\n",
    "print(f\"Precision: {test_precision:.3f}\")\n",
    "print(f\"Recall:    {test_recall:.3f}\")\n",
    "print(f\"F1:        {test_f1:.3f}\")\n",
    "print(classification_report(y_test, y_test_pred_optimal, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed:\n",
    "\n",
    "1. Model Selection: Wanted to mirror the other momentum shift study by choosing the same/similar model to train. In the other study it just says its an artificial neural network with \"N = 4 and k = 7, and the 4 input variables are win probability, time in the quarter, score difference, and total points scored to that point in the game (by both teams) and the desired output is the probability of positive momentum\".\n",
    "    -Multilayer Perceptron chosen using scikit. Forward feed neural network, many parameters to work with\n",
    "2. Trained model using small number of selected features. Bad results, 0 on f1, recall and precision for predicting momentum shifts class. \n",
    "3. Trained model using all features. Still bad results, but better than before. f1, recall and precision all got higher than before\n",
    "4. Trained model using all features and using the prediction probabilities to test automatically test different thresholds. \n",
    "    -Difference in results. \n",
    "        Non Threshold Training: Not catching many momentum shifts class, but precision was fairly high (.26 recall, .72 precision, f1-score .39)\n",
    "        Threshold Training: Catching almost 70% the momentum shifts, but precision lowered by a lot (.66 recall, .38 precision, f1-score .48)\n",
    "        Conclusion: The non threshold training is very accurate but doesnt detect the minority momentum shift class enough. The threshold training catches more momentum shifts but the at a much lower true positive rate. I cant really decide which would be better at this moment, so i hypertuned both to see if we could get better results.\n",
    "5. Hypertuning Parameters\n",
    "    -Grid Search for hypertuning and Group K Fold cross validation/seperating game data to ensure no leakage\n",
    "        Non-Threshold Hyper Tuning: \n",
    "        Threshold Hyper Tuning: Better results, still not great\n",
    "        *All results in CSV\n",
    "\n",
    "\n",
    "\n",
    "Ensemble approach for data imbalanced\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
