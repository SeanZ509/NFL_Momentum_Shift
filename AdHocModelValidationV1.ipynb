{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanz\\AppData\\Local\\Temp\\ipykernel_21300\\4107407487.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['field_goal_result'].fillna('none', inplace=True)\n",
      "C:\\Users\\seanz\\AppData\\Local\\Temp\\ipykernel_21300\\4107407487.py:521: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '548.7808836884615' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  dfV5.at[index, 'Home_Momentum_Score'] = dfV5.at[index - 1, 'Home_Momentum_Score'] + home_momentum_gain\n",
      "C:\\Users\\seanz\\AppData\\Local\\Temp\\ipykernel_21300\\4107407487.py:522: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '489.3937295340633' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  dfV5.at[index, 'Away_Momentum_Score'] = dfV5.at[index - 1, 'Away_Momentum_Score'] + away_momentum_gain\n",
      "C:\\Users\\seanz\\AppData\\Local\\Temp\\ipykernel_21300\\4107407487.py:575: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  dfV5 = dfV5.groupby('game_id', group_keys=False).apply(detect_momentum_shifts)\n",
      "C:\\Users\\seanz\\AppData\\Local\\Temp\\ipykernel_21300\\4107407487.py:583: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dfV5[columns_to_fill] = dfV5[columns_to_fill].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv('NFL_pbp_2009-2019.csv', low_memory=False)\n",
    "\n",
    "threshold = 100000\n",
    "df['field_goal_result'].fillna('none', inplace=True)\n",
    "dfV2 = df.loc[:, df.isnull().sum() < threshold]\n",
    "missing_values = dfV2.isnull().sum()\n",
    "\n",
    "statistical_cols = ['play_id', 'game_id', 'home_team', 'away_team', 'posteam', \n",
    "                    'defteam', 'side_of_field', 'yardline_100', 'half_seconds_remaining', \n",
    "                    'game_seconds_remaining', 'game_half', 'drive', 'qtr', 'down', 'goal_to_go', 'time', \n",
    "                    'yrdln', 'ydstogo', 'ydsnet', 'desc', 'play_type', 'yards_gained', 'home_timeouts_remaining', \n",
    "                    'away_timeouts_remaining', 'total_home_score',  'total_away_score', 'score_differential', 'home_wp', 'away_wp', 'ep']\n",
    "\n",
    "game_dynamics_cols = [\n",
    "    'punt_blocked', 'first_down_rush', 'first_down_pass', 'first_down_penalty', 'third_down_converted',\n",
    "    'third_down_failed', 'fourth_down_converted', 'fourth_down_failed', 'incomplete_pass', 'interception',\n",
    "    'fumble_forced', 'fumble_not_forced', 'fumble_out_of_bounds', 'solo_tackle', 'safety', 'penalty',\n",
    "    'tackled_for_loss', 'fumble_lost', 'own_kickoff_recovery', 'own_kickoff_recovery_td', 'qb_hit',\n",
    "    'rush_attempt', 'pass_attempt', 'sack', 'touchdown', 'pass_touchdown', 'rush_touchdown', 'field_goal_result',\n",
    "    'return_touchdown', 'extra_point_attempt', 'two_point_attempt', 'field_goal_attempt', 'kickoff_attempt',\n",
    "    'punt_attempt', 'fumble', 'complete_pass', 'shotgun', 'no_huddle', 'punt_inside_twenty', 'kickoff_inside_twenty']\n",
    "\n",
    "columns_to_keep = statistical_cols + game_dynamics_cols\n",
    "dfV3 = dfV2[columns_to_keep]\n",
    "\n",
    "dfV4 = dfV3.drop(['play_id', 'game_seconds_remaining', 'fumble_forced'], axis=1)\n",
    "dfV4 = dfV4.dropna(subset=['down', 'defteam', 'posteam'])\n",
    "dfV4 = dfV4.reset_index(drop=True)\n",
    "\n",
    "# Indicators for if within last 2 minutes of the half and the whole game\n",
    "dfV4['close_to_end_of_half'] = (dfV4['half_seconds_remaining'] <= 120).astype(int)\n",
    "dfV4['close_to_end_of_game'] = ((dfV4['half_seconds_remaining'] <= 120) & (dfV4['game_half'] == 'Half2')).astype(int)\n",
    "\n",
    "# Indicator for if the touchdown was for the away or home team\n",
    "dfV4['home_td'] = ((dfV4['touchdown'] == 1) & (dfV4['posteam'] != dfV4['away_team'])).astype(int)\n",
    "dfV4['away_td'] = ((dfV4['touchdown'] == 1) & (dfV4['posteam'] != dfV4['home_team'])).astype(int)\n",
    "\n",
    "# Trackers for the difference in both teams' win probability after each play\n",
    "dfV4['home_wp_change'] = dfV4['home_wp'].diff().fillna(0)\n",
    "dfV4['away_wp_change'] = dfV4['away_wp'].diff().fillna(0)\n",
    "\n",
    "# Indicator for turnover\n",
    "dfV4['turnover'] = (\n",
    "    (dfV4['safety'] == 1) |\n",
    "    (dfV4['interception'] == 1) |\n",
    "    (dfV4['fumble_lost'] == 1) |\n",
    "    ((dfV4['fourth_down_converted'] == 0) & (dfV4['down'] == 4))\n",
    ").astype(int)\n",
    "\n",
    "# Drive time - Added drive ended indicator to help - Manually resets after end of game, half, and change of possession\n",
    "dfV4['drive_ended'] = (\n",
    "    (dfV4['posteam'] != dfV4['posteam'].shift(1)) |  \n",
    "    (dfV4['game_id'] != dfV4['game_id'].shift(1)) |  \n",
    "    dfV4['desc'].str.contains('END GAME', na=False) |  \n",
    "    dfV4['desc'].str.contains('END QUARTER', na=False)  \n",
    ").astype(int)\n",
    "dfV4['drive'] = (\n",
    "    (dfV4['posteam'].ne(dfV4['posteam'].shift())) |\n",
    "    (dfV4['game_id'].ne(dfV4['game_id'].shift()))\n",
    ").cumsum()\n",
    "dfV4['drive_time_seconds'] = (\n",
    "    dfV4.groupby(['game_id', 'drive'])['half_seconds_remaining']\n",
    "    .transform('first') - dfV4['half_seconds_remaining']\n",
    ")\n",
    "dfV4['drive_time_seconds'] = dfV4.apply(\n",
    "    lambda row: 0 if row['drive_ended'] == 1 else row['drive_time_seconds'], axis=1\n",
    ")\n",
    "dfV4['drive_time_seconds'] = dfV4.groupby(['game_id', 'drive'])['drive_time_seconds'].cumsum()\n",
    "\n",
    "# Indicator for long touchdowns\n",
    "dfV4['long_td'] = ((dfV4['touchdown'] == 1) & (dfV4['yards_gained'] >= 50)).astype(int)\n",
    "\n",
    "# Trackers for score differentials and lead changes\n",
    "dfV4['home_score_differential'] = dfV4['total_home_score'] - dfV4['total_away_score']\n",
    "dfV4['away_score_differential'] = -dfV4['home_score_differential']\n",
    "dfV4['lead_change'] = ((dfV4['home_score_differential'].diff() < 0) &\n",
    "                       (dfV4['home_score_differential'].shift() * dfV4['home_score_differential'] < 0)).astype(int)\n",
    "\n",
    "# Combining first down indicators\n",
    "dfV4['first_down'] = ((dfV4['first_down_pass'] == 1) | (dfV4['first_down_rush'] == 1) | (dfV4['first_down_penalty'] == 1)).astype(int)\n",
    "\n",
    "# Indicators for scoring drives - Removing\n",
    "dfV4['home_scoring_drive'] = (\n",
    "    (dfV4['home_td'] == 1) \n",
    ").astype(int)\n",
    "dfV4['away_scoring_drive'] = (\n",
    "    (dfV4['away_td'] == 1) \n",
    ").astype(int)\n",
    "\n",
    "# Helper for consecutive scoring events - Remove Later!!!!!!!!!!!!!!\n",
    "dfV4['home_scoring_events'] = (\n",
    "    (dfV4['posteam'] != dfV4['away_team']) & \n",
    "    ((dfV4['home_td'] == 1) | (dfV4['field_goal_result'] == 'made'))\n",
    ").astype(int)\n",
    "dfV4['away_scoring_events'] = (\n",
    "    (dfV4['posteam'] != dfV4['home_team']) & \n",
    "    ((dfV4['away_td'] == 1) | (dfV4['field_goal_result'] == 'made'))\n",
    ").astype(int)\n",
    "\n",
    "# Consecutive Scoring Events + Helper function \n",
    "def calc_consecutive_cumsum_with_game_reset(series, reset_series, game_ids):\n",
    "    cumsum = 0\n",
    "    consecutive = []\n",
    "    prev_game_id = None  \n",
    "    \n",
    "    for i in range(len(series)):\n",
    "        if game_ids[i] != prev_game_id:\n",
    "            cumsum = 0 \n",
    "        if reset_series[i] == 1:  \n",
    "            cumsum = 0\n",
    "        if series[i] == 1:  \n",
    "            cumsum += 1\n",
    "        consecutive.append(cumsum)\n",
    "        prev_game_id = game_ids[i]  \n",
    "    return consecutive\n",
    "\n",
    "dfV4['home_csum_scores'] = calc_consecutive_cumsum_with_game_reset(\n",
    "    dfV4['home_scoring_events'], dfV4['away_scoring_events'], dfV4['game_id']\n",
    ")\n",
    "dfV4['away_csum_scores'] = calc_consecutive_cumsum_with_game_reset(\n",
    "    dfV4['away_scoring_events'], dfV4['home_scoring_events'], dfV4['game_id']\n",
    ")\n",
    "\n",
    "#Consecutive defensive stops\n",
    "dfV4['home_def_stop'] = (\n",
    "    (dfV4['posteam'] != dfV4['home_team']) &  ((dfV4['punt_attempt'] == 1) |  (dfV4['turnover'] == 1)) & \n",
    "    ~dfV4['field_goal_result'].isin(['made'])  \n",
    ").astype(int)\n",
    "dfV4['away_def_stop'] = (\n",
    "    (dfV4['posteam'] != dfV4['away_team']) & ((dfV4['punt_attempt'] == 1) |  (dfV4['turnover'] == 1)) & \n",
    "    ~dfV4['field_goal_result'].isin(['made'])\n",
    ").astype(int)\n",
    "\n",
    "def calc_consecutive_defensive_stops_with_game_reset(series, reset_series, game_ids):\n",
    "    cumsum = 0\n",
    "    consecutive = []\n",
    "    prev_game_id = None  \n",
    "    for i in range(len(series)):\n",
    "        if game_ids[i] != prev_game_id:\n",
    "            cumsum = 0\n",
    "        if reset_series[i] == 1:\n",
    "            cumsum = 0\n",
    "        if series[i] == 1:\n",
    "            cumsum += 1\n",
    "        consecutive.append(cumsum)\n",
    "        prev_game_id = game_ids[i]  \n",
    "    return consecutive\n",
    "\n",
    "dfV4['home_csum_def_stops'] = calc_consecutive_defensive_stops_with_game_reset(\n",
    "    dfV4['home_def_stop'], dfV4['away_scoring_events'], dfV4['game_id']\n",
    ")\n",
    "dfV4['away_csum_def_stops'] = calc_consecutive_defensive_stops_with_game_reset(\n",
    "    dfV4['away_def_stop'], dfV4['home_scoring_events'], dfV4['game_id']\n",
    ")\n",
    "\n",
    "# Home/Away Drive Numbers\n",
    "dfV4['away_drive_number'] = (\n",
    "    dfV4.loc[dfV4['posteam'] != dfV4['home_team']]\n",
    "    .groupby('game_id')['drive_ended'].cumsum()\n",
    ")\n",
    "dfV4['home_drive_number'] = (\n",
    "    dfV4.loc[dfV4['posteam'] == dfV4['home_team']]\n",
    "    .groupby('game_id')['drive_ended'].cumsum()\n",
    ")\n",
    "\n",
    "# Offense needs to score\n",
    "dfV4['off_need_score'] = (\n",
    "    (dfV4['down'].isin([3, 4])) & \n",
    "    (abs(dfV4['score_differential']) <= 8) & \n",
    "    (dfV4['qtr'] >= 4) &\n",
    "    (dfV4['first_down'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Defense Needs a Stop\n",
    "dfV4['def_need_stop'] = (\n",
    "    (dfV4['down'].isin([3, 4])) & \n",
    "    (abs(dfV4['score_differential']) <= 8) & \n",
    "    (dfV4['qtr'] >= 4) &\n",
    "    (dfV4['turnover'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Drought Ending score\n",
    "dfV4['drought_end_play'] = (\n",
    "    ((dfV4['away_csum_scores'].shift(1) >= 2) & (dfV4['away_csum_scores'] == 0) & (dfV4['home_scoring_events'] == 1)) |\n",
    "    ((dfV4['home_csum_scores'].shift(1) >= 2) & (dfV4['home_csum_scores'] == 0) & (dfV4['away_scoring_events'] == 1))\n",
    ").astype(int)\n",
    "\n",
    "# Defensive touchdown\n",
    "dfV4['def_td'] = (\n",
    "    ((dfV4['fumble'] == 1) & (dfV4['return_touchdown'] == 1)) |\n",
    "    ((dfV4['interception'] == 1) & (dfV4['return_touchdown'] == 1))\n",
    ").astype(int)\n",
    "\n",
    "# Defensive touchdown\n",
    "dfV4['off_td'] = (\n",
    "    (dfV4['pass_touchdown'] == 1) | (dfV4['rush_touchdown'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Special Teams touchdown\n",
    "dfV4['st_return_td'] = (\n",
    "    ((dfV4['kickoff_attempt'] == 1) & (dfV4['return_touchdown'] == 1)) | \n",
    "    ((dfV4['punt_attempt'] == 1) & (dfV4['return_touchdown'] == 1))  \n",
    ").astype(int)\n",
    "\n",
    "# Big special teams play...punt blocked, field goal blocked, return_touchdown, kick recovery, pin team near endzone\n",
    "dfV4['big_st_play'] = (\n",
    "    (dfV4['punt_blocked'] == 1) | \n",
    "    (dfV4['field_goal_result'] == 'blocked') | \n",
    "    (dfV4['own_kickoff_recovery'] == 1) | \n",
    "    (dfV4['st_return_td'] == 1) | \n",
    "    (dfV4['kickoff_inside_twenty'] == 1) | \n",
    "    (dfV4['punt_inside_twenty'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Scoring type differentiatior, touchdowns should hold more weight than a field goal, other types may hold more weight also\n",
    "dfV4['scoring_type'] = np.select(\n",
    "    [\n",
    "        dfV4['field_goal_result'] == 'made',\n",
    "        dfV4['off_td'] == 1,\n",
    "        dfV4['def_td'] == 1,\n",
    "        dfV4['st_return_td'] == 1,\n",
    "    ],\n",
    "    ['fg', 'off_td', 'def_td', 'st_td'],\n",
    "    default='none'\n",
    ")\n",
    "\n",
    "# Indicator for big offensive play\n",
    "dfV4['big_offensive_play'] = (\n",
    "        (dfV4['yards_gained'] >= 40) |\n",
    "        (dfV4['long_td'] == 1) |\n",
    "        ((dfV4['off_need_score'] == 1) & (dfV4['off_td'] == 1))\n",
    ").astype(int)\n",
    "\n",
    "# Indicator for big defensive play\n",
    "dfV4['big_defensive_play'] = (\n",
    "    (dfV4['sack'] == 1) |\n",
    "    (dfV4['tackled_for_loss'] == 1) |\n",
    "    ((dfV4['def_need_stop'] == 1) & ((dfV4['def_td'] == 'def_td')) | dfV4['turnover'] == 1) |\n",
    "    (dfV4['scoring_type'] == 'def_td')\n",
    ").astype(int)\n",
    "\n",
    "#Quick Score and Quick Stop #### Needs fixing, only want 1 on last play of drive when they score or get stop, right now 1 for whole drive\n",
    "dfV4['total_drive_time'] = dfV4.groupby('drive')['drive_time_seconds'].transform('last') \n",
    "dfV4['cumulative_drive_time'] = dfV4.groupby(['game_id', 'drive'])['drive_time_seconds'].cumsum()\n",
    "dfV4['long_drive_triggered'] = (\n",
    "    dfV4.groupby(['game_id', 'drive'])['cumulative_drive_time']\n",
    "    .transform(lambda x: (x > 360).idxmax() == x.index)  # Flags the first row that exceeds 360s\n",
    ").astype(int)\n",
    "\n",
    "dfV4['quick_score'] = (\n",
    "    (dfV4['drive_time_seconds'] < 180) &\n",
    "    ((dfV4['touchdown'] == 1) | (dfV4['field_goal_result'] == 'made')) &\n",
    "    (dfV4.groupby('drive')['drive_time_seconds'].transform('last') == dfV4['drive_time_seconds'])\n",
    ").astype(int)\n",
    "dfV4['quick_stop'] = (\n",
    "    (dfV4['total_drive_time'] < 180) & \n",
    "    (dfV4['scoring_type'] == 'none') &\n",
    "    (dfV4.groupby('drive')['drive_time_seconds'].transform('last') == dfV4['drive_time_seconds'])\n",
    ").astype(int)\n",
    "\n",
    "# Consecutive first downs\n",
    "dfV4['home_csum_first_downs'] = 0\n",
    "dfV4['away_csum_first_downs'] = 0\n",
    "dfV4['home_csum_first_downs'] = (\n",
    "    dfV4.groupby(['home_team', 'away_team', 'home_drive_number'])['first_down']\n",
    "    .cumsum()\n",
    "    .where(dfV4['posteam'] != 'away_team', 0)\n",
    ")\n",
    "dfV4['away_csum_first_downs'] = (\n",
    "    dfV4.groupby(['home_team', 'away_team', 'away_drive_number'])['first_down']\n",
    "    .cumsum()\n",
    "    .where(dfV4['posteam'] != 'home_team', 0)\n",
    ")\n",
    "\n",
    "\n",
    "columns_to_remove = [\n",
    "    'ep', 'punt_blocked', 'first_down_rush', 'first_down_pass', \n",
    "    'third_down_converted', 'third_down_failed', 'fourth_down_converted', \n",
    "    'fourth_down_failed', 'incomplete_pass', 'interception', 'fumble_not_forced', \n",
    "    'fumble_out_of_bounds', 'solo_tackle', 'safety', 'penalty', 'tackled_for_loss', \n",
    "    'fumble_lost', 'own_kickoff_recovery', 'own_kickoff_recovery_td', 'qb_hit', \n",
    "    'rush_attempt', 'pass_attempt', 'sack', 'extra_point_attempt', 'two_point_attempt', \n",
    "    'field_goal_attempt', 'kickoff_attempt', 'punt_attempt', 'fumble', 'pass_touchdown', 'rush_touchdown'\n",
    "    'complete_pass', 'shotgun', 'home_scoring_drive', 'away_scoring_drive','home_scoring_events','away_scoring_events',\n",
    "    'rush_touchdown', 'field_goal_result', 'return_touchdown', 'complete_pass', 'no_huddle', 'punt_inside_twenty', 'kickoff_inside_twenty',\n",
    "    'time', 'yrdln', 'ydstogo', 'ydsnet', 'desc', 'side_of_field', 'yardline_100', 'desc', 'drive', 'game_half', 'drive_ended', 'drive_time_seconds',\n",
    "    'touchdown', 'score_differential', 'total_drive_time'\n",
    "]\n",
    "\n",
    "dfV5 = dfV4.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "dynamics = [\n",
    "    ('big_offensive_play', dfV5['big_offensive_play'] == 1),\n",
    "    ('big_defensive_play', dfV5['big_defensive_play'] == 1),\n",
    "    ('off_td', dfV5['off_td'] == 1),\n",
    "    ('def_td', dfV5['def_td'] == 1),\n",
    "    ('big_st_play', dfV5['big_st_play'] == 1),\n",
    "    ('st_return_td', dfV5['st_return_td'] == 1),\n",
    "    ('off_need_score', dfV5['off_need_score'] == 1),\n",
    "    ('def_need_stop', dfV5['def_need_stop'] == 1),\n",
    "    ('drought_end_play', dfV5['drought_end_play'] == 1),\n",
    "    ('home_csum_scores', dfV5['home_csum_scores'] >= 2),\n",
    "    ('away_csum_scores', dfV5['away_csum_scores'] >= 2),\n",
    "    ('home_csum_def_stops', dfV5['home_csum_def_stops'] >= 2),\n",
    "    ('away_csum_def_stops', dfV5['away_csum_def_stops'] >= 2),\n",
    "    ('home_csum_first_downs', dfV5['home_csum_first_downs'] >= 2),\n",
    "    ('away_csum_first_downs', dfV5['away_csum_first_downs'] >= 2),\n",
    "    ('long_td', dfV5['long_td'] == 1),\n",
    "    ('quick_score', dfV5['quick_score'] == 1),\n",
    "    ('quick_stop', dfV5['quick_stop'] == 1),\n",
    "    ('home_score_differential', dfV5['home_score_differential'] == 1),\n",
    "    ('away_score_differential', dfV5['away_score_differential'] == 1),\n",
    "]\n",
    "\n",
    "\n",
    "def_wp_change = {\n",
    "    \"big_defensive_play\": 0.029471,\n",
    "    \"def_td\": 0.016322,\n",
    "    \"big_st_play\": 0.034637,\n",
    "    \"st_return_td\": 0.040082,\n",
    "    \"def_need_stop\": 0.042132,\n",
    "    \"quick_stop\": 0.029971\n",
    "}\n",
    "\n",
    "off_wp_change = {\n",
    "    \"big_offensive_play\": 0.038602,\n",
    "    \"off_td\": 0.028432,\n",
    "    \"off_need_score\":  0.035536, \n",
    "    \"drought_end_play\": 0.028891,\n",
    "    \"long_td\": 0.033325,\n",
    "    \"quick_score\": 0.026664\n",
    "}\n",
    "\n",
    "streaks_multipliers = {\n",
    "    \"home_csum_scores\": 1.118986,\n",
    "    \"away_csum_scores\": 1.118986,\n",
    "    \"home_csum_first_downs\": 1.1112094,\n",
    "    \"away_csum_first_downs\": 1.1112094,\n",
    "    \"home_csum_def_stops\": 1.111932,\n",
    "    \"away_csum_def_stops\": 1.111932,\n",
    "}\n",
    "\n",
    "score_game_multipliers = {\n",
    "    \"tied_or_1_score\": 1.06634844,\n",
    "    \"2_score\": 1.035777727,\n",
    "    \"3_or_more_score\": 1.0274060\n",
    "}\n",
    "\n",
    "qtr_multipliers = {\n",
    "    \"first_and_fourth\": 1.5522285,\n",
    "    \"second_and_third\": 1.3201836\n",
    "}\n",
    "\n",
    "home_away_multipliers = {\n",
    "    \"home\": 1.07949869,  \n",
    "    \"away\": 1.06027507 \n",
    "}\n",
    "\n",
    "boost_case_multipliers = {\n",
    "    \"home_and_4th\": 1.122276683,  \n",
    "    \"away_and_1st\": 1.16675933,  \n",
    "    \"none\": 1.0           \n",
    "}\n",
    "\n",
    "decay_multipliers = {\n",
    "    \"opponent_scores\": 0.68004571,\n",
    "    \"turnover\": 0.21742678,\n",
    "    \"opponent_ends_drought\": 0.18212307,\n",
    "    \"long_possession\":  0.1534018395,\n",
    "    \"none\": 0.0  \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def calculate_multipliers(row, index, category, is_offensive):\n",
    "    if abs(row['home_score_differential']) <= 8:\n",
    "        S = score_game_multipliers[\"tied_or_1_score\"]\n",
    "    elif 9 <= abs(row['home_score_differential']) <= 16:\n",
    "        S = score_game_multipliers[\"2_score\"]\n",
    "    else:\n",
    "        S = score_game_multipliers[\"3_or_more_score\"]\n",
    "\n",
    "    team = row['posteam'] if is_offensive else row['defteam']\n",
    "    HA = home_away_multipliers.get(team, 1.0)\n",
    "\n",
    "    if row['qtr'] == 1 or row['qtr'] == 4:\n",
    "        Q = qtr_multipliers[\"first_and_fourth\"]\n",
    "    else:\n",
    "        Q = qtr_multipliers[\"second_and_third\"]\n",
    "\n",
    "    if is_offensive:\n",
    "        if row['posteam'] == 'home' and row['qtr'] == 4:\n",
    "            B = boost_case_multipliers[\"home_and_4th\"]\n",
    "        elif row['posteam'] == 'away' and row['qtr'] == 1:\n",
    "            B = boost_case_multipliers[\"away_and_1st\"]\n",
    "        else:\n",
    "            B = 1.0\n",
    "    else:\n",
    "        if team == 'home' and row['qtr'] == 4:\n",
    "            B = boost_case_multipliers[\"home_and_4th\"]\n",
    "        elif team == 'away' and row['qtr'] == 1:\n",
    "            B = boost_case_multipliers[\"away_and_1st\"]\n",
    "        else:\n",
    "            B = 1.0\n",
    "\n",
    "    CS = 1.0\n",
    "   \n",
    "    if is_offensive:\n",
    "        if row['posteam'] == row['home_team']:\n",
    "            if row['home_csum_scores'] >= 2:\n",
    "                if row['home_csum_scores'] > dfV5.at[index - 1, 'home_csum_scores']: \n",
    "                    CS = streaks_multipliers['home_csum_scores']\n",
    "            elif row['home_csum_first_downs'] >= 4:\n",
    "                if row['home_csum_first_downs'] > dfV5.at[index - 1, 'home_csum_first_downs']: \n",
    "                    CS = streaks_multipliers['home_csum_first_downs']\n",
    "            else:\n",
    "                CS = 1.0\n",
    "        else:\n",
    "            if row['away_csum_scores'] >= 2:\n",
    "                if row['away_csum_scores'] > dfV5.at[index - 1, 'away_csum_scores']: \n",
    "                    CS = streaks_multipliers['away_csum_scores']\n",
    "            elif row['away_csum_first_downs'] >= 4:\n",
    "                if row['away_csum_first_downs'] >  dfV5.at[index - 1, 'away_csum_first_downs']: \n",
    "                    CS = streaks_multipliers['away_csum_first_downs']\n",
    "            else:\n",
    "                CS = 1.0\n",
    "    else:\n",
    "        if row['defteam'] == row['home_team']:\n",
    "            if row['home_csum_def_stops'] >= 2:\n",
    "                if row['home_csum_def_stops'] > dfV5.at[index - 1, 'home_csum_def_stops']: \n",
    "                    CS = streaks_multipliers['home_csum_def_stops']\n",
    "            else:\n",
    "                CS = 1.0\n",
    "        else:\n",
    "            if row['away_csum_def_stops'] >= 2:\n",
    "                if row['away_csum_def_stops'] > dfV5.at[index - 1, 'away_csum_def_stops']:\n",
    "                    CS = streaks_multipliers['away_csum_def_stops']\n",
    "            else:\n",
    "                CS = 1.0\n",
    "\n",
    "    return S, HA, B, CS, Q\n",
    "\n",
    "\n",
    "\n",
    "def calculate_momentum_gain(wp_change_value, S, HA, CS, B, Q):\n",
    "    return wp_change_value * (S * HA * CS * B * Q) * 1000\n",
    "\n",
    "\n",
    "\n",
    "def calculate_decay(row, category, momentum_gain):\n",
    "    if category in ['off_td', 'long_td', 'def_td', 'st_return_td']:\n",
    "        D = decay_multipliers['opponent_scores']\n",
    "    elif row['turnover'] == 1:\n",
    "        D = decay_multipliers['turnover']\n",
    "    elif row['drought_end_play'] == 1:\n",
    "        D = decay_multipliers[\"opponent_ends_drought\"]\n",
    "    elif row['long_drive_triggered'] == 1:  \n",
    "        D = decay_multipliers['long_possession']\n",
    "    else:\n",
    "        D = decay_multipliers['none']\n",
    "\n",
    "    return momentum_gain * D\n",
    "\n",
    "\n",
    "\n",
    "def update_momentum_scores(dfV5):\n",
    "    dfV5['Home_Momentum_Score'] = 500\n",
    "    dfV5['Away_Momentum_Score'] = 500\n",
    "\n",
    "    dfV5['game_id_diff'] = dfV5['game_id'] != dfV5['game_id'].shift(1)\n",
    "\n",
    "    for index, row in dfV5.iterrows():\n",
    "        if index == 0:  \n",
    "            continue\n",
    "\n",
    "        if row['game_id_diff']:\n",
    "            dfV5.at[index, 'Home_Momentum_Score'] = 500\n",
    "            dfV5.at[index, 'Away_Momentum_Score'] = 500\n",
    "            continue\n",
    "\n",
    "        home_momentum_gain = 0\n",
    "        away_momentum_gain = 0\n",
    "\n",
    "        for category, wp_change_value in off_wp_change.items():\n",
    "            if row[category] == 1:\n",
    "                S, HA, B, CS, Q = calculate_multipliers(row, index, category, True)\n",
    "                momentum_gain = calculate_momentum_gain(wp_change_value, S, HA, CS, B, Q)\n",
    "                momentum_loss = calculate_decay(row, category, momentum_gain)\n",
    "\n",
    "                if row['posteam'] == row['home_team']:\n",
    "                    home_momentum_gain += momentum_gain\n",
    "                    away_momentum_gain -= momentum_loss\n",
    "                else:\n",
    "                    away_momentum_gain += momentum_gain\n",
    "                    home_momentum_gain -= momentum_loss\n",
    "\n",
    "        for category, wp_change_value in def_wp_change.items():\n",
    "            if row[category] == 1:\n",
    "                S, HA, B, CS, Q = calculate_multipliers(row, index, category, False)\n",
    "                momentum_gain = calculate_momentum_gain(wp_change_value, S, HA, CS, B, Q)\n",
    "                momentum_loss = calculate_decay(row, category, momentum_gain)\n",
    "\n",
    "                if row['defteam'] == row['home_team']:\n",
    "                    home_momentum_gain += momentum_gain\n",
    "                    away_momentum_gain -= momentum_loss\n",
    "                else:\n",
    "                    away_momentum_gain += momentum_gain\n",
    "                    home_momentum_gain -= momentum_loss\n",
    "\n",
    "        dfV5.at[index, 'Home_Momentum_Score'] = dfV5.at[index - 1, 'Home_Momentum_Score'] + home_momentum_gain\n",
    "        dfV5.at[index, 'Away_Momentum_Score'] = dfV5.at[index - 1, 'Away_Momentum_Score'] + away_momentum_gain\n",
    "\n",
    "update_momentum_scores(dfV5)\n",
    "\n",
    "dfV5['Game_Momentum_Diff'] = 0\n",
    "\n",
    "historical_max_diff_mean = dfV5.groupby('game_id')['Game_Momentum_Diff'].max().mean()\n",
    "historical_max_diff_std = dfV5.groupby('game_id')['Game_Momentum_Diff'].max().std()\n",
    "\n",
    "base_threshold = historical_max_diff_mean + 0.8 * historical_max_diff_std #.7\n",
    "\n",
    "dfV5['Game_Momentum_Diff'] = abs(dfV5['Home_Momentum_Score'] - dfV5['Away_Momentum_Score'])\n",
    "dfV5['Dynamic_Threshold'] = None\n",
    "dfV5['Momentum_Holding_Team'] = None\n",
    "\n",
    "def detect_momentum_shifts(game_data):\n",
    "    momentum_holding_team = None\n",
    "    last_shift_home_momentum = game_data.iloc[0]['Home_Momentum_Score']\n",
    "    last_shift_away_momentum = game_data.iloc[0]['Away_Momentum_Score']\n",
    "    max_momentum_diff_so_far = 0\n",
    "\n",
    "    for i in range(1, len(game_data)): \n",
    "        if i < 10:  # Ignore shifts for the first 10 plays\n",
    "            continue\n",
    "        home_momentum_diff = game_data.iloc[i]['Home_Momentum_Score'] - last_shift_home_momentum\n",
    "        away_momentum_diff = game_data.iloc[i]['Away_Momentum_Score'] - last_shift_away_momentum        \n",
    "\n",
    "        current_momentum_diff = abs(game_data.iloc[i]['Home_Momentum_Score'] - game_data.iloc[i]['Away_Momentum_Score'])\n",
    "        max_momentum_diff_so_far = max(max_momentum_diff_so_far, current_momentum_diff)\n",
    "        game_threshold = max(base_threshold, 0.8 * max_momentum_diff_so_far) #.7\n",
    "        game_data.iloc[i, game_data.columns.get_loc('Dynamic_Threshold')] = game_threshold\n",
    "\n",
    "        home_momentum_shift = False\n",
    "        away_momentum_shift = False\n",
    "\n",
    "        if home_momentum_diff >= game_threshold and away_momentum_diff < game_threshold * 0.8: #.5\n",
    "            home_momentum_shift = True\n",
    "        elif away_momentum_diff >= game_threshold and home_momentum_diff < game_threshold * 0.8: #.5\n",
    "            away_momentum_shift = True\n",
    "\n",
    "        if home_momentum_shift:\n",
    "            momentum_holding_team = \"Home\"\n",
    "            last_shift_home_momentum = game_data.iloc[i]['Home_Momentum_Score']\n",
    "            last_shift_away_momentum = game_data.iloc[i]['Away_Momentum_Score']\n",
    "        elif away_momentum_shift:\n",
    "            momentum_holding_team = \"Away\"\n",
    "            last_shift_home_momentum = game_data.iloc[i]['Home_Momentum_Score']\n",
    "            last_shift_away_momentum = game_data.iloc[i]['Away_Momentum_Score']\n",
    "\n",
    "        game_data.iloc[i, game_data.columns.get_loc('Momentum_Holding_Team')] = momentum_holding_team\n",
    "\n",
    "    return game_data\n",
    "\n",
    "dfV5 = dfV5.groupby('game_id', group_keys=False).apply(detect_momentum_shifts)\n",
    "\n",
    "dfV5['Momentum_Shift_Occurred'] = dfV5.groupby('game_id')['Momentum_Holding_Team'].transform(\n",
    "    lambda x: x.ne(x.shift()) & x.notna()\n",
    ")\n",
    "\n",
    "columns_to_fill = ['home_drive_number', 'away_drive_number', 'home_csum_first_downs', \n",
    "                    'away_csum_first_downs', 'Dynamic_Threshold', 'yards_gained']\n",
    "dfV5[columns_to_fill] = dfV5[columns_to_fill].fillna(0)\n",
    "\n",
    "features = dfV5.drop(['Momentum_Shift_Occurred'], axis=1)  \n",
    "numeric_df = dfV5.select_dtypes(include=[np.number])\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(numeric_df)\n",
    "\n",
    "df = dfV5.copy()\n",
    "\n",
    "excluded_cols = ['game_id', 'Momentum_Shift_Occurred', 'Momentum_Holding_Team']\n",
    "target_col = 'Momentum_Shift_Occurred'\n",
    "feature_df = df.drop(columns=excluded_cols, errors='ignore')\n",
    "\n",
    "numeric_cols = feature_df.select_dtypes(include=['number']).columns\n",
    "categorical_cols = feature_df.select_dtypes(exclude=['number']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    feature_df = pd.get_dummies(feature_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "unique_games = df['game_id'].unique()\n",
    "unique_games_sorted = sorted(unique_games)\n",
    "train_size = int(0.8 * len(unique_games_sorted))\n",
    "train_games = unique_games_sorted[:train_size]\n",
    "test_games = unique_games_sorted[train_size:]\n",
    "\n",
    "feature_df['game_id'] = df['game_id']\n",
    "train_features = feature_df[feature_df['game_id'].isin(train_games)].drop(columns='game_id')\n",
    "test_features = feature_df[feature_df['game_id'].isin(test_games)].drop(columns='game_id')\n",
    "X_train = train_features.values\n",
    "X_test = test_features.values\n",
    "y_train = df.loc[df['game_id'].isin(train_games), target_col].astype(int).values\n",
    "y_test = df.loc[df['game_id'].isin(test_games), target_col].astype(int).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Train Set with Corrected ±4 Play Window ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    331300\n",
      "           1       0.69      0.77      0.73      6975\n",
      "\n",
      "    accuracy                           0.99    338275\n",
      "   macro avg       0.84      0.88      0.86    338275\n",
      "weighted avg       0.99      0.99      0.99    338275\n",
      "\n",
      "\n",
      "=== Test Set with Corrected ±4 Play Window ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     82061\n",
      "           1       0.51      0.42      0.46      1726\n",
      "\n",
      "    accuracy                           0.98     83787\n",
      "   macro avg       0.75      0.71      0.73     83787\n",
      "weighted avg       0.98      0.98      0.98     83787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import maximum_filter1d\n",
    "\n",
    "df = dfV5.copy()\n",
    "\n",
    "excluded_cols = ['game_id', 'Momentum_Shift_Occurred', 'Momentum_Holding_Team']\n",
    "target_col = 'Momentum_Shift_Occurred'\n",
    "feature_df = df.drop(columns=excluded_cols, errors='ignore')\n",
    "\n",
    "numeric_cols = feature_df.select_dtypes(include=['number']).columns\n",
    "categorical_cols = feature_df.select_dtypes(exclude=['number']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    feature_df = pd.get_dummies(feature_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "unique_games = df['game_id'].unique()\n",
    "unique_games_sorted = sorted(unique_games)\n",
    "train_size = int(0.8 * len(unique_games_sorted))\n",
    "train_games = unique_games_sorted[:train_size]\n",
    "test_games = unique_games_sorted[train_size:]\n",
    "\n",
    "feature_df['game_id'] = df['game_id']\n",
    "train_features = feature_df[feature_df['game_id'].isin(train_games)].drop(columns='game_id')\n",
    "test_features = feature_df[feature_df['game_id'].isin(test_games)].drop(columns='game_id')\n",
    "X_train = train_features.values\n",
    "X_test = test_features.values\n",
    "y_train = df.loc[df['game_id'].isin(train_games), target_col].astype(int).values\n",
    "y_test = df.loc[df['game_id'].isin(test_games), target_col].astype(int).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(32, 16), alpha=0.001, solver='adam', max_iter=500, random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_proba = mlp.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_proba = mlp.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "y_train_pred_threshold = (y_train_proba >= 0.16842105263157897).astype(int)\n",
    "y_test_pred_threshold = (y_test_proba >= 0.16842105263157897).astype(int)\n",
    "\n",
    "def apply_temporal_correction(preds, actuals, window_size=4):\n",
    "    corrected_preds = np.zeros_like(preds)\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_size)\n",
    "        end = min(len(preds), i + window_size + 1)\n",
    "        if preds[i] == 1 and np.any(actuals[start:end] == 1):\n",
    "            corrected_preds[i] = 1 \n",
    "    return corrected_preds\n",
    "\n",
    "y_train_pred_corrected = apply_temporal_correction(y_train_pred_threshold, y_train)\n",
    "y_test_pred_corrected = apply_temporal_correction(y_test_pred_threshold, y_test)\n",
    "\n",
    "print(\"\\n=== Train Set with Corrected ±4 Play Window ===\")\n",
    "print(classification_report(y_train, y_train_pred_corrected, zero_division=0))\n",
    "\n",
    "print(\"\\n=== Test Set with Corrected ±4 Play Window ===\")\n",
    "print(classification_report(y_test, y_test_pred_corrected, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:54:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Train Set Performance (Before Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    331300\n",
      "           1       0.78      1.00      0.88      6975\n",
      "\n",
      "    accuracy                           0.99    338275\n",
      "   macro avg       0.89      1.00      0.94    338275\n",
      "weighted avg       1.00      0.99      0.99    338275\n",
      "\n",
      "\n",
      "=== Test Set Performance (Before Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     82061\n",
      "           1       0.49      0.52      0.51      1726\n",
      "\n",
      "    accuracy                           0.98     83787\n",
      "   macro avg       0.74      0.75      0.75     83787\n",
      "weighted avg       0.98      0.98      0.98     83787\n",
      "\n",
      "\n",
      "=== Train Set Performance (After Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    331300\n",
      "           1       0.86      1.00      0.93      6975\n",
      "\n",
      "    accuracy                           1.00    338275\n",
      "   macro avg       0.93      1.00      0.96    338275\n",
      "weighted avg       1.00      1.00      1.00    338275\n",
      "\n",
      "\n",
      "=== Test Set Performance (After Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     82061\n",
      "           1       0.70      0.52      0.60      1726\n",
      "\n",
      "    accuracy                           0.99     83787\n",
      "   macro avg       0.84      0.76      0.79     83787\n",
      "weighted avg       0.98      0.99      0.98     83787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "best_params = {\n",
    "    'subsample': 0.6,\n",
    "    'scale_pos_weight': 7,\n",
    "    'n_estimators': 300,\n",
    "    'min_child_weight': 5,\n",
    "    'max_depth': 12,\n",
    "    'learning_rate': 0.05,\n",
    "    'gamma': 0.1,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': 1,\n",
    "    'use_label_encoder': False,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(**best_params)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_threshold = 0.5\n",
    "y_train_proba = xgb_model.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_proba = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "y_train_pred = (y_train_proba >= best_threshold).astype(int)\n",
    "y_test_pred = (y_test_proba >= best_threshold).astype(int)\n",
    "\n",
    "def apply_temporal_correction(preds, actuals, window_size=4):\n",
    "    corrected_preds = np.zeros_like(preds)\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_size)\n",
    "        end = min(len(preds), i + window_size + 1)\n",
    "        if preds[i] == 1 and np.any(actuals[start:end] == 1):\n",
    "            corrected_preds[i] = 1\n",
    "    return corrected_preds\n",
    "\n",
    "y_train_corrected = apply_temporal_correction(y_train_pred, y_train)\n",
    "y_test_corrected = apply_temporal_correction(y_test_pred, y_test)\n",
    "\n",
    "print(\"\\n=== Train Set Performance (Before Temporal Correction) ===\")\n",
    "print(classification_report(y_train, y_train_pred, zero_division=0))\n",
    "\n",
    "print(\"\\n=== Test Set Performance (Before Temporal Correction) ===\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))\n",
    "\n",
    "print(\"\\n=== Train Set Performance (After Temporal Correction) ===\")\n",
    "print(classification_report(y_train, y_train_corrected, zero_division=0))\n",
    "\n",
    "print(\"\\n=== Test Set Performance (After Temporal Correction) ===\")\n",
    "print(classification_report(y_test, y_test_corrected, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertuning LGBoost, Random Forest, and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[LightGBM] [Info] Number of positive: 6975, number of negative: 331300\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.159357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3682\n",
      "[LightGBM] [Info] Number of data points in the train set: 338275, number of used features: 198\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020619 -> initscore=-3.860692\n",
      "[LightGBM] [Info] Start training from score -3.860692\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best LGBM: {'subsample': 0.6, 'scale_pos_weight': 5, 'n_estimators': 300, 'min_child_weight': 5, 'max_depth': 12, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "Best RF: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 25, 'class_weight': 'balanced'}\n",
      "Best Logistic Regression: {'solver': 'saga', 'penalty': 'l1', 'class_weight': 'balanced', 'C': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "lgbm_param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"max_depth\": [6, 10, 12],\n",
    "    \"min_child_weight\": [1, 3, 5],\n",
    "    \"subsample\": [0.6, 0.8],\n",
    "    \"colsample_bytree\": [0.6, 0.9],\n",
    "    \"scale_pos_weight\": [5, 7, 10]\n",
    "}\n",
    "\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [10, 20, 25],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"class_weight\": [\"balanced\"]\n",
    "}\n",
    "\n",
    "logreg_param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1.0, 10.0],\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"solver\": [\"liblinear\", \"saga\"],\n",
    "    \"class_weight\": [\"balanced\"]\n",
    "}\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "lgbm_search = RandomizedSearchCV(lgbm, lgbm_param_grid, n_iter=10, scoring='f1', cv=3, n_jobs=-1, verbose=1)\n",
    "rf_search = RandomizedSearchCV(rf, rf_param_grid, n_iter=10, scoring='f1', cv=3, n_jobs=-1, verbose=1)\n",
    "logreg_search = RandomizedSearchCV(logreg, logreg_param_grid, n_iter=10, scoring='f1', cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "lgbm_search.fit(X_train_scaled, y_train)\n",
    "rf_search.fit(X_train_scaled, y_train)\n",
    "logreg_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_lgbm = lgbm_search.best_estimator_\n",
    "best_rf = rf_search.best_estimator_\n",
    "best_logreg = logreg_search.best_estimator_\n",
    "\n",
    "print(\"Best LGBM:\", lgbm_search.best_params_)\n",
    "print(\"Best RF:\", rf_search.best_params_)\n",
    "print(\"Best Logistic Regression:\", logreg_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked all models (XGB, RF, LGBM, MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\seanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\seanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best Classification Threshold Found: 0.90 (F1-Score: 0.4211) ===\n",
      "\n",
      "=== Train Set Performance (Before Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98    331300\n",
      "           1       0.34      0.99      0.51      6975\n",
      "\n",
      "    accuracy                           0.96    338275\n",
      "   macro avg       0.67      0.97      0.74    338275\n",
      "weighted avg       0.99      0.96      0.97    338275\n",
      "\n",
      "\n",
      "=== Test Set Performance (Before Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     82061\n",
      "           1       0.28      0.81      0.42      1726\n",
      "\n",
      "    accuracy                           0.95     83787\n",
      "   macro avg       0.64      0.88      0.70     83787\n",
      "weighted avg       0.98      0.95      0.96     83787\n",
      "\n",
      "\n",
      "=== Train Set Performance (After Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    331300\n",
      "           1       0.60      0.99      0.74      6975\n",
      "\n",
      "    accuracy                           0.99    338275\n",
      "   macro avg       0.80      0.99      0.87    338275\n",
      "weighted avg       0.99      0.99      0.99    338275\n",
      "\n",
      "\n",
      "=== Test Set Performance (After Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     82061\n",
      "           1       0.55      0.81      0.66      1726\n",
      "\n",
      "    accuracy                           0.98     83787\n",
      "   macro avg       0.77      0.90      0.82     83787\n",
      "weighted avg       0.99      0.98      0.98     83787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=[('xgb', xgb_model), ('rf', best_rf), ('lgbm', best_lgbm), ('mlp', mlp)],\n",
    "    final_estimator=best_logreg,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacked_model.fit(X_train_scaled, y_train)\n",
    "y_train_proba = stacked_model.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_proba = stacked_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "threshold_values = np.linspace(0.1, 0.9, 9)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in threshold_values:\n",
    "    y_test_pred_threshold = (y_test_proba >= threshold).astype(int)\n",
    "    f1 = classification_report(y_test, y_test_pred_threshold, output_dict=True)[\"1\"][\"f1-score\"]\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\n=== Best Classification Threshold Found: {best_threshold:.2f} (F1-Score: {best_f1:.4f}) ===\")\n",
    "y_train_pred_threshold = (y_train_proba >= best_threshold).astype(int)\n",
    "y_test_pred_threshold = (y_test_proba >= best_threshold).astype(int)\n",
    "\n",
    "def apply_temporal_correction(preds, actuals, window_size=4):\n",
    "    corrected_preds = np.zeros_like(preds)\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_size)\n",
    "        end = min(len(preds), i + window_size + 1)\n",
    "        if preds[i] == 1 and np.any(actuals[start:end] == 1):\n",
    "            corrected_preds[i] = 1  \n",
    "    return corrected_preds\n",
    "\n",
    "y_train_pred_corrected = apply_temporal_correction(y_train_pred_threshold, y_train)\n",
    "y_test_pred_corrected = apply_temporal_correction(y_test_pred_threshold, y_test)\n",
    "\n",
    "print(\"\\n=== Train Set Performance (Before Temporal Correction) ===\")\n",
    "print(classification_report(y_train, y_train_pred_threshold, zero_division=0))\n",
    "\n",
    "print(\"\\n=== Test Set Performance (Before Temporal Correction) ===\")\n",
    "print(classification_report(y_test, y_test_pred_threshold, zero_division=0))\n",
    "\n",
    "print(\"\\n=== Train Set Performance (After Temporal Correction) ===\")\n",
    "print(classification_report(y_train, y_train_pred_corrected, zero_division=0))\n",
    "\n",
    "print(\"\\n=== Test Set Performance (After Temporal Correction) ===\")\n",
    "print(classification_report(y_test, y_test_pred_corrected, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked First Choices(XGB, RF, MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best Classification Threshold Found: 0.90 (F1-Score: 0.3354) ===\n",
      "\n",
      "=== Train Set Performance (Before Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97    331300\n",
      "           1       0.26      1.00      0.41      6975\n",
      "\n",
      "    accuracy                           0.94    338275\n",
      "   macro avg       0.63      0.97      0.69    338275\n",
      "weighted avg       0.98      0.94      0.96    338275\n",
      "\n",
      "\n",
      "=== Test Set Performance (Before Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     82061\n",
      "           1       0.21      0.85      0.34      1726\n",
      "\n",
      "    accuracy                           0.93     83787\n",
      "   macro avg       0.60      0.89      0.65     83787\n",
      "weighted avg       0.98      0.93      0.95     83787\n",
      "\n",
      "\n",
      "=== Train Set Performance (After Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    331300\n",
      "           1       0.52      1.00      0.68      6975\n",
      "\n",
      "    accuracy                           0.98    338275\n",
      "   macro avg       0.76      0.99      0.84    338275\n",
      "weighted avg       0.99      0.98      0.98    338275\n",
      "\n",
      "\n",
      "=== Test Set Performance (After Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     82061\n",
      "           1       0.47      0.85      0.60      1726\n",
      "\n",
      "    accuracy                           0.98     83787\n",
      "   macro avg       0.73      0.92      0.80     83787\n",
      "weighted avg       0.99      0.98      0.98     83787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stacked_model = StackingClassifier(\n",
    "    estimators=[('xgb', xgb_model), ('rf', best_rf), ('mlp', mlp)],\n",
    "    final_estimator=best_logreg,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacked_model.fit(X_train_scaled, y_train)\n",
    "y_train_proba = stacked_model.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_proba = stacked_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "threshold_values = np.linspace(0.1, 0.9, 9)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in threshold_values:\n",
    "    y_test_pred_threshold = (y_test_proba >= threshold).astype(int)\n",
    "    f1 = classification_report(y_test, y_test_pred_threshold, output_dict=True)[\"1\"][\"f1-score\"]\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\n=== Best Classification Threshold Found: {best_threshold:.2f} (F1-Score: {best_f1:.4f}) ===\")\n",
    "y_train_pred_threshold = (y_train_proba >= best_threshold).astype(int)\n",
    "y_test_pred_threshold = (y_test_proba >= best_threshold).astype(int)\n",
    "\n",
    "def apply_temporal_correction(preds, actuals, window_size=4):\n",
    "    corrected_preds = np.zeros_like(preds)\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_size)\n",
    "        end = min(len(preds), i + window_size + 1)\n",
    "        if preds[i] == 1 and np.any(actuals[start:end] == 1):\n",
    "            corrected_preds[i] = 1  \n",
    "    return corrected_preds\n",
    "\n",
    "y_train_pred_corrected = apply_temporal_correction(y_train_pred_threshold, y_train)\n",
    "y_test_pred_corrected = apply_temporal_correction(y_test_pred_threshold, y_test)\n",
    "\n",
    "print(\"\\n=== Train Set Performance (Before Temporal Correction) ===\")\n",
    "print(classification_report(y_train, y_train_pred_threshold, zero_division=0))\n",
    "\n",
    "print(\"\\n=== Test Set Performance (Before Temporal Correction) ===\")\n",
    "print(classification_report(y_test, y_test_pred_threshold, zero_division=0))\n",
    "\n",
    "print(\"\\n=== Train Set Performance (After Temporal Correction) ===\")\n",
    "print(classification_report(y_train, y_train_pred_corrected, zero_division=0))\n",
    "\n",
    "print(\"\\n=== Test Set Performance (After Temporal Correction) ===\")\n",
    "print(classification_report(y_test, y_test_pred_corrected, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Trees Only(XGB, RF, LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\seanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\seanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best Classification Threshold Found: 0.90 (F1-Score: 0.4541) ===\n",
      "\n",
      "=== Train Set Performance (Before Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    331300\n",
      "           1       0.41      1.00      0.58      6975\n",
      "\n",
      "    accuracy                           0.97    338275\n",
      "   macro avg       0.71      0.98      0.78    338275\n",
      "weighted avg       0.99      0.97      0.98    338275\n",
      "\n",
      "\n",
      "=== Test Set Performance (Before Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     82061\n",
      "           1       0.32      0.76      0.45      1726\n",
      "\n",
      "    accuracy                           0.96     83787\n",
      "   macro avg       0.66      0.86      0.72     83787\n",
      "weighted avg       0.98      0.96      0.97     83787\n",
      "\n",
      "\n",
      "=== Train Set Performance (After Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    331300\n",
      "           1       0.65      1.00      0.79      6975\n",
      "\n",
      "    accuracy                           0.99    338275\n",
      "   macro avg       0.83      0.99      0.89    338275\n",
      "weighted avg       0.99      0.99      0.99    338275\n",
      "\n",
      "\n",
      "=== Test Set Performance (After Temporal Correction) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     82061\n",
      "           1       0.58      0.76      0.66      1726\n",
      "\n",
      "    accuracy                           0.98     83787\n",
      "   macro avg       0.79      0.87      0.82     83787\n",
      "weighted avg       0.99      0.98      0.98     83787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stacked_model = StackingClassifier(\n",
    "    estimators=[('xgb', xgb_model), ('rf', best_rf), ('lgbm', best_lgbm)],\n",
    "    final_estimator=best_logreg,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacked_model.fit(X_train_scaled, y_train)\n",
    "y_train_proba = stacked_model.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_proba = stacked_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "threshold_values = np.linspace(0.1, 0.9, 9)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in threshold_values:\n",
    "    y_test_pred_threshold = (y_test_proba >= threshold).astype(int)\n",
    "    f1 = classification_report(y_test, y_test_pred_threshold, output_dict=True)[\"1\"][\"f1-score\"]\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\n=== Best Classification Threshold Found: {best_threshold:.2f} (F1-Score: {best_f1:.4f}) ===\")\n",
    "y_train_pred_threshold = (y_train_proba >= best_threshold).astype(int)\n",
    "y_test_pred_threshold = (y_test_proba >= best_threshold).astype(int)\n",
    "\n",
    "def apply_temporal_correction(preds, actuals, window_size=4):\n",
    "    corrected_preds = np.zeros_like(preds)\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window_size)\n",
    "        end = min(len(preds), i + window_size + 1)\n",
    "        if preds[i] == 1 and np.any(actuals[start:end] == 1):\n",
    "            corrected_preds[i] = 1  \n",
    "    return corrected_preds\n",
    "\n",
    "y_train_pred_corrected = apply_temporal_correction(y_train_pred_threshold, y_train)\n",
    "y_test_pred_corrected = apply_temporal_correction(y_test_pred_threshold, y_test)\n",
    "\n",
    "print(\"\\n=== Train Set Performance (Before Temporal Correction) ===\")\n",
    "print(classification_report(y_train, y_train_pred_threshold, zero_division=0))\n",
    "\n",
    "print(\"\\n=== Test Set Performance (Before Temporal Correction) ===\")\n",
    "print(classification_report(y_test, y_test_pred_threshold, zero_division=0))\n",
    "\n",
    "print(\"\\n=== Train Set Performance (After Temporal Correction) ===\")\n",
    "print(classification_report(y_train, y_train_pred_corrected, zero_division=0))\n",
    "\n",
    "print(\"\\n=== Test Set Performance (After Temporal Correction) ===\")\n",
    "print(classification_report(y_test, y_test_pred_corrected, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
