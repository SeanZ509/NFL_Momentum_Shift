{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanz\\AppData\\Local\\Temp\\ipykernel_13860\\2755329174.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['field_goal_result'].fillna('none', inplace=True)\n",
      "C:\\Users\\seanz\\AppData\\Local\\Temp\\ipykernel_13860\\2755329174.py:521: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '548.7808836884615' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  dfV5.at[index, 'Home_Momentum_Score'] = dfV5.at[index - 1, 'Home_Momentum_Score'] + home_momentum_gain\n",
      "C:\\Users\\seanz\\AppData\\Local\\Temp\\ipykernel_13860\\2755329174.py:522: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '489.3937295340633' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  dfV5.at[index, 'Away_Momentum_Score'] = dfV5.at[index - 1, 'Away_Momentum_Score'] + away_momentum_gain\n",
      "C:\\Users\\seanz\\AppData\\Local\\Temp\\ipykernel_13860\\2755329174.py:575: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  dfV5 = dfV5.groupby('game_id', group_keys=False).apply(detect_momentum_shifts)\n",
      "C:\\Users\\seanz\\AppData\\Local\\Temp\\ipykernel_13860\\2755329174.py:583: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dfV5[columns_to_fill] = dfV5[columns_to_fill].fillna(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>PC14</th>\n",
       "      <th>PC15</th>\n",
       "      <th>PC16</th>\n",
       "      <th>PC17</th>\n",
       "      <th>PC18</th>\n",
       "      <th>PC19</th>\n",
       "      <th>PC20</th>\n",
       "      <th>PC21</th>\n",
       "      <th>PC22</th>\n",
       "      <th>PC23</th>\n",
       "      <th>PC24</th>\n",
       "      <th>PC25</th>\n",
       "      <th>PC26</th>\n",
       "      <th>PC27</th>\n",
       "      <th>PC28</th>\n",
       "      <th>PC29</th>\n",
       "      <th>PC30</th>\n",
       "      <th>Momentum_Shift_Occurred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.502194</td>\n",
       "      <td>-3.218508</td>\n",
       "      <td>-0.044483</td>\n",
       "      <td>-0.692268</td>\n",
       "      <td>0.207728</td>\n",
       "      <td>0.617730</td>\n",
       "      <td>-0.095790</td>\n",
       "      <td>-0.244981</td>\n",
       "      <td>0.253502</td>\n",
       "      <td>-0.905387</td>\n",
       "      <td>-1.129721</td>\n",
       "      <td>0.761692</td>\n",
       "      <td>-0.316661</td>\n",
       "      <td>0.775689</td>\n",
       "      <td>0.529774</td>\n",
       "      <td>0.099472</td>\n",
       "      <td>2.245678</td>\n",
       "      <td>0.057101</td>\n",
       "      <td>-0.596545</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.106489</td>\n",
       "      <td>0.182943</td>\n",
       "      <td>0.267666</td>\n",
       "      <td>-0.104805</td>\n",
       "      <td>0.543723</td>\n",
       "      <td>-0.244041</td>\n",
       "      <td>-0.033606</td>\n",
       "      <td>0.612715</td>\n",
       "      <td>0.095361</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.428102</td>\n",
       "      <td>-3.246133</td>\n",
       "      <td>0.211228</td>\n",
       "      <td>-0.427948</td>\n",
       "      <td>0.206565</td>\n",
       "      <td>0.619298</td>\n",
       "      <td>0.392401</td>\n",
       "      <td>-0.273335</td>\n",
       "      <td>-0.108111</td>\n",
       "      <td>-0.083365</td>\n",
       "      <td>-0.978670</td>\n",
       "      <td>0.892659</td>\n",
       "      <td>-0.029448</td>\n",
       "      <td>-0.045745</td>\n",
       "      <td>0.487501</td>\n",
       "      <td>0.066728</td>\n",
       "      <td>-0.285052</td>\n",
       "      <td>0.317987</td>\n",
       "      <td>-0.058645</td>\n",
       "      <td>-0.122947</td>\n",
       "      <td>0.307805</td>\n",
       "      <td>-0.098938</td>\n",
       "      <td>0.218983</td>\n",
       "      <td>0.119934</td>\n",
       "      <td>-0.352395</td>\n",
       "      <td>0.675005</td>\n",
       "      <td>-0.245362</td>\n",
       "      <td>-0.029322</td>\n",
       "      <td>0.568054</td>\n",
       "      <td>0.084004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.196172</td>\n",
       "      <td>-3.057688</td>\n",
       "      <td>1.820782</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>0.171288</td>\n",
       "      <td>0.602331</td>\n",
       "      <td>0.510450</td>\n",
       "      <td>-0.785140</td>\n",
       "      <td>-0.151083</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>-0.968615</td>\n",
       "      <td>0.976115</td>\n",
       "      <td>-0.060222</td>\n",
       "      <td>-0.286907</td>\n",
       "      <td>0.489112</td>\n",
       "      <td>-0.026622</td>\n",
       "      <td>-0.186035</td>\n",
       "      <td>0.236064</td>\n",
       "      <td>0.102568</td>\n",
       "      <td>-0.559631</td>\n",
       "      <td>1.016895</td>\n",
       "      <td>0.141309</td>\n",
       "      <td>0.302030</td>\n",
       "      <td>0.146483</td>\n",
       "      <td>-0.556321</td>\n",
       "      <td>0.652954</td>\n",
       "      <td>-0.219550</td>\n",
       "      <td>-0.090924</td>\n",
       "      <td>-0.206692</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.521493</td>\n",
       "      <td>-2.918547</td>\n",
       "      <td>4.443888</td>\n",
       "      <td>1.935242</td>\n",
       "      <td>0.949298</td>\n",
       "      <td>0.537175</td>\n",
       "      <td>2.031028</td>\n",
       "      <td>0.302749</td>\n",
       "      <td>0.057638</td>\n",
       "      <td>0.453378</td>\n",
       "      <td>-0.444415</td>\n",
       "      <td>1.154558</td>\n",
       "      <td>-0.003316</td>\n",
       "      <td>-0.032604</td>\n",
       "      <td>0.331423</td>\n",
       "      <td>-0.483051</td>\n",
       "      <td>-0.276693</td>\n",
       "      <td>-0.191189</td>\n",
       "      <td>-0.417322</td>\n",
       "      <td>-2.645951</td>\n",
       "      <td>-0.819220</td>\n",
       "      <td>0.260691</td>\n",
       "      <td>-0.118316</td>\n",
       "      <td>-0.071153</td>\n",
       "      <td>-0.277915</td>\n",
       "      <td>0.423098</td>\n",
       "      <td>-0.209122</td>\n",
       "      <td>-0.245814</td>\n",
       "      <td>-1.100681</td>\n",
       "      <td>-0.606992</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.170653</td>\n",
       "      <td>-3.158175</td>\n",
       "      <td>-0.832833</td>\n",
       "      <td>-0.398895</td>\n",
       "      <td>-0.329927</td>\n",
       "      <td>0.098929</td>\n",
       "      <td>-1.306571</td>\n",
       "      <td>0.874564</td>\n",
       "      <td>-1.304541</td>\n",
       "      <td>3.139035</td>\n",
       "      <td>0.899681</td>\n",
       "      <td>0.905133</td>\n",
       "      <td>-2.938221</td>\n",
       "      <td>0.742369</td>\n",
       "      <td>0.451527</td>\n",
       "      <td>-0.209335</td>\n",
       "      <td>1.523188</td>\n",
       "      <td>-0.790911</td>\n",
       "      <td>3.285815</td>\n",
       "      <td>-1.212305</td>\n",
       "      <td>0.865374</td>\n",
       "      <td>-1.474200</td>\n",
       "      <td>0.939521</td>\n",
       "      <td>-0.462161</td>\n",
       "      <td>-0.172800</td>\n",
       "      <td>1.062859</td>\n",
       "      <td>0.305143</td>\n",
       "      <td>-0.017631</td>\n",
       "      <td>1.443531</td>\n",
       "      <td>-0.090435</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0 -2.502194 -3.218508 -0.044483 -0.692268  0.207728  0.617730 -0.095790   \n",
       "1 -2.428102 -3.246133  0.211228 -0.427948  0.206565  0.619298  0.392401   \n",
       "2 -2.196172 -3.057688  1.820782  0.013693  0.171288  0.602331  0.510450   \n",
       "3 -1.521493 -2.918547  4.443888  1.935242  0.949298  0.537175  2.031028   \n",
       "4 -2.170653 -3.158175 -0.832833 -0.398895 -0.329927  0.098929 -1.306571   \n",
       "\n",
       "        PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
       "0 -0.244981  0.253502 -0.905387 -1.129721  0.761692 -0.316661  0.775689   \n",
       "1 -0.273335 -0.108111 -0.083365 -0.978670  0.892659 -0.029448 -0.045745   \n",
       "2 -0.785140 -0.151083  0.007881 -0.968615  0.976115 -0.060222 -0.286907   \n",
       "3  0.302749  0.057638  0.453378 -0.444415  1.154558 -0.003316 -0.032604   \n",
       "4  0.874564 -1.304541  3.139035  0.899681  0.905133 -2.938221  0.742369   \n",
       "\n",
       "       PC15      PC16      PC17      PC18      PC19      PC20      PC21  \\\n",
       "0  0.529774  0.099472  2.245678  0.057101 -0.596545  0.007475  0.006780   \n",
       "1  0.487501  0.066728 -0.285052  0.317987 -0.058645 -0.122947  0.307805   \n",
       "2  0.489112 -0.026622 -0.186035  0.236064  0.102568 -0.559631  1.016895   \n",
       "3  0.331423 -0.483051 -0.276693 -0.191189 -0.417322 -2.645951 -0.819220   \n",
       "4  0.451527 -0.209335  1.523188 -0.790911  3.285815 -1.212305  0.865374   \n",
       "\n",
       "       PC22      PC23      PC24      PC25      PC26      PC27      PC28  \\\n",
       "0  0.106489  0.182943  0.267666 -0.104805  0.543723 -0.244041 -0.033606   \n",
       "1 -0.098938  0.218983  0.119934 -0.352395  0.675005 -0.245362 -0.029322   \n",
       "2  0.141309  0.302030  0.146483 -0.556321  0.652954 -0.219550 -0.090924   \n",
       "3  0.260691 -0.118316 -0.071153 -0.277915  0.423098 -0.209122 -0.245814   \n",
       "4 -1.474200  0.939521 -0.462161 -0.172800  1.062859  0.305143 -0.017631   \n",
       "\n",
       "       PC29      PC30  Momentum_Shift_Occurred  \n",
       "0  0.612715  0.095361                    False  \n",
       "1  0.568054  0.084004                    False  \n",
       "2 -0.206692  0.003514                    False  \n",
       "3 -1.100681 -0.606992                    False  \n",
       "4  1.443531 -0.090435                    False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv('NFL_pbp_2009-2019.csv', low_memory=False)\n",
    "\n",
    "threshold = 100000\n",
    "df['field_goal_result'].fillna('none', inplace=True)\n",
    "dfV2 = df.loc[:, df.isnull().sum() < threshold]\n",
    "missing_values = dfV2.isnull().sum()\n",
    "\n",
    "statistical_cols = ['play_id', 'game_id', 'home_team', 'away_team', 'posteam', \n",
    "                    'defteam', 'side_of_field', 'yardline_100', 'half_seconds_remaining', \n",
    "                    'game_seconds_remaining', 'game_half', 'drive', 'qtr', 'down', 'goal_to_go', 'time', \n",
    "                    'yrdln', 'ydstogo', 'ydsnet', 'desc', 'play_type', 'yards_gained', 'home_timeouts_remaining', \n",
    "                    'away_timeouts_remaining', 'total_home_score',  'total_away_score', 'score_differential', 'home_wp', 'away_wp', 'ep']\n",
    "\n",
    "game_dynamics_cols = [\n",
    "    'punt_blocked', 'first_down_rush', 'first_down_pass', 'first_down_penalty', 'third_down_converted',\n",
    "    'third_down_failed', 'fourth_down_converted', 'fourth_down_failed', 'incomplete_pass', 'interception',\n",
    "    'fumble_forced', 'fumble_not_forced', 'fumble_out_of_bounds', 'solo_tackle', 'safety', 'penalty',\n",
    "    'tackled_for_loss', 'fumble_lost', 'own_kickoff_recovery', 'own_kickoff_recovery_td', 'qb_hit',\n",
    "    'rush_attempt', 'pass_attempt', 'sack', 'touchdown', 'pass_touchdown', 'rush_touchdown', 'field_goal_result',\n",
    "    'return_touchdown', 'extra_point_attempt', 'two_point_attempt', 'field_goal_attempt', 'kickoff_attempt',\n",
    "    'punt_attempt', 'fumble', 'complete_pass', 'shotgun', 'no_huddle', 'punt_inside_twenty', 'kickoff_inside_twenty']\n",
    "\n",
    "columns_to_keep = statistical_cols + game_dynamics_cols\n",
    "dfV3 = dfV2[columns_to_keep]\n",
    "\n",
    "dfV4 = dfV3.drop(['play_id', 'game_seconds_remaining', 'fumble_forced'], axis=1)\n",
    "dfV4 = dfV4.dropna(subset=['down', 'defteam', 'posteam'])\n",
    "dfV4 = dfV4.reset_index(drop=True)\n",
    "\n",
    "# Indicators for if within last 2 minutes of the half and the whole game\n",
    "dfV4['close_to_end_of_half'] = (dfV4['half_seconds_remaining'] <= 120).astype(int)\n",
    "dfV4['close_to_end_of_game'] = ((dfV4['half_seconds_remaining'] <= 120) & (dfV4['game_half'] == 'Half2')).astype(int)\n",
    "\n",
    "# Indicator for if the touchdown was for the away or home team\n",
    "dfV4['home_td'] = ((dfV4['touchdown'] == 1) & (dfV4['posteam'] != dfV4['away_team'])).astype(int)\n",
    "dfV4['away_td'] = ((dfV4['touchdown'] == 1) & (dfV4['posteam'] != dfV4['home_team'])).astype(int)\n",
    "\n",
    "# Trackers for the difference in both teams' win probability after each play\n",
    "dfV4['home_wp_change'] = dfV4['home_wp'].diff().fillna(0)\n",
    "dfV4['away_wp_change'] = dfV4['away_wp'].diff().fillna(0)\n",
    "\n",
    "# Indicator for turnover\n",
    "dfV4['turnover'] = (\n",
    "    (dfV4['safety'] == 1) |\n",
    "    (dfV4['interception'] == 1) |\n",
    "    (dfV4['fumble_lost'] == 1) |\n",
    "    ((dfV4['fourth_down_converted'] == 0) & (dfV4['down'] == 4))\n",
    ").astype(int)\n",
    "\n",
    "# Drive time - Added drive ended indicator to help - Manually resets after end of game, half, and change of possession\n",
    "dfV4['drive_ended'] = (\n",
    "    (dfV4['posteam'] != dfV4['posteam'].shift(1)) |  \n",
    "    (dfV4['game_id'] != dfV4['game_id'].shift(1)) |  \n",
    "    dfV4['desc'].str.contains('END GAME', na=False) |  \n",
    "    dfV4['desc'].str.contains('END QUARTER', na=False)  \n",
    ").astype(int)\n",
    "dfV4['drive'] = (\n",
    "    (dfV4['posteam'].ne(dfV4['posteam'].shift())) |\n",
    "    (dfV4['game_id'].ne(dfV4['game_id'].shift()))\n",
    ").cumsum()\n",
    "dfV4['drive_time_seconds'] = (\n",
    "    dfV4.groupby(['game_id', 'drive'])['half_seconds_remaining']\n",
    "    .transform('first') - dfV4['half_seconds_remaining']\n",
    ")\n",
    "dfV4['drive_time_seconds'] = dfV4.apply(\n",
    "    lambda row: 0 if row['drive_ended'] == 1 else row['drive_time_seconds'], axis=1\n",
    ")\n",
    "dfV4['drive_time_seconds'] = dfV4.groupby(['game_id', 'drive'])['drive_time_seconds'].cumsum()\n",
    "\n",
    "# Indicator for long touchdowns\n",
    "dfV4['long_td'] = ((dfV4['touchdown'] == 1) & (dfV4['yards_gained'] >= 50)).astype(int)\n",
    "\n",
    "# Trackers for score differentials and lead changes\n",
    "dfV4['home_score_differential'] = dfV4['total_home_score'] - dfV4['total_away_score']\n",
    "dfV4['away_score_differential'] = -dfV4['home_score_differential']\n",
    "dfV4['lead_change'] = ((dfV4['home_score_differential'].diff() < 0) &\n",
    "                       (dfV4['home_score_differential'].shift() * dfV4['home_score_differential'] < 0)).astype(int)\n",
    "\n",
    "# Combining first down indicators\n",
    "dfV4['first_down'] = ((dfV4['first_down_pass'] == 1) | (dfV4['first_down_rush'] == 1) | (dfV4['first_down_penalty'] == 1)).astype(int)\n",
    "\n",
    "# Indicators for scoring drives - Removing\n",
    "dfV4['home_scoring_drive'] = (\n",
    "    (dfV4['home_td'] == 1) \n",
    ").astype(int)\n",
    "dfV4['away_scoring_drive'] = (\n",
    "    (dfV4['away_td'] == 1) \n",
    ").astype(int)\n",
    "\n",
    "# Helper for consecutive scoring events - Remove Later!!!!!!!!!!!!!!\n",
    "dfV4['home_scoring_events'] = (\n",
    "    (dfV4['posteam'] != dfV4['away_team']) & \n",
    "    ((dfV4['home_td'] == 1) | (dfV4['field_goal_result'] == 'made'))\n",
    ").astype(int)\n",
    "dfV4['away_scoring_events'] = (\n",
    "    (dfV4['posteam'] != dfV4['home_team']) & \n",
    "    ((dfV4['away_td'] == 1) | (dfV4['field_goal_result'] == 'made'))\n",
    ").astype(int)\n",
    "\n",
    "# Consecutive Scoring Events + Helper function \n",
    "def calc_consecutive_cumsum_with_game_reset(series, reset_series, game_ids):\n",
    "    cumsum = 0\n",
    "    consecutive = []\n",
    "    prev_game_id = None  \n",
    "    \n",
    "    for i in range(len(series)):\n",
    "        if game_ids[i] != prev_game_id:\n",
    "            cumsum = 0 \n",
    "        if reset_series[i] == 1:  \n",
    "            cumsum = 0\n",
    "        if series[i] == 1:  \n",
    "            cumsum += 1\n",
    "        consecutive.append(cumsum)\n",
    "        prev_game_id = game_ids[i]  \n",
    "    return consecutive\n",
    "\n",
    "dfV4['home_csum_scores'] = calc_consecutive_cumsum_with_game_reset(\n",
    "    dfV4['home_scoring_events'], dfV4['away_scoring_events'], dfV4['game_id']\n",
    ")\n",
    "dfV4['away_csum_scores'] = calc_consecutive_cumsum_with_game_reset(\n",
    "    dfV4['away_scoring_events'], dfV4['home_scoring_events'], dfV4['game_id']\n",
    ")\n",
    "\n",
    "#Consecutive defensive stops\n",
    "dfV4['home_def_stop'] = (\n",
    "    (dfV4['posteam'] != dfV4['home_team']) &  ((dfV4['punt_attempt'] == 1) |  (dfV4['turnover'] == 1)) & \n",
    "    ~dfV4['field_goal_result'].isin(['made'])  \n",
    ").astype(int)\n",
    "dfV4['away_def_stop'] = (\n",
    "    (dfV4['posteam'] != dfV4['away_team']) & ((dfV4['punt_attempt'] == 1) |  (dfV4['turnover'] == 1)) & \n",
    "    ~dfV4['field_goal_result'].isin(['made'])\n",
    ").astype(int)\n",
    "\n",
    "def calc_consecutive_defensive_stops_with_game_reset(series, reset_series, game_ids):\n",
    "    cumsum = 0\n",
    "    consecutive = []\n",
    "    prev_game_id = None  \n",
    "    for i in range(len(series)):\n",
    "        if game_ids[i] != prev_game_id:\n",
    "            cumsum = 0\n",
    "        if reset_series[i] == 1:\n",
    "            cumsum = 0\n",
    "        if series[i] == 1:\n",
    "            cumsum += 1\n",
    "        consecutive.append(cumsum)\n",
    "        prev_game_id = game_ids[i]  \n",
    "    return consecutive\n",
    "\n",
    "dfV4['home_csum_def_stops'] = calc_consecutive_defensive_stops_with_game_reset(\n",
    "    dfV4['home_def_stop'], dfV4['away_scoring_events'], dfV4['game_id']\n",
    ")\n",
    "dfV4['away_csum_def_stops'] = calc_consecutive_defensive_stops_with_game_reset(\n",
    "    dfV4['away_def_stop'], dfV4['home_scoring_events'], dfV4['game_id']\n",
    ")\n",
    "\n",
    "# Home/Away Drive Numbers\n",
    "dfV4['away_drive_number'] = (\n",
    "    dfV4.loc[dfV4['posteam'] != dfV4['home_team']]\n",
    "    .groupby('game_id')['drive_ended'].cumsum()\n",
    ")\n",
    "dfV4['home_drive_number'] = (\n",
    "    dfV4.loc[dfV4['posteam'] == dfV4['home_team']]\n",
    "    .groupby('game_id')['drive_ended'].cumsum()\n",
    ")\n",
    "\n",
    "# Offense needs to score\n",
    "dfV4['off_need_score'] = (\n",
    "    (dfV4['down'].isin([3, 4])) & \n",
    "    (abs(dfV4['score_differential']) <= 8) & \n",
    "    (dfV4['qtr'] >= 4) &\n",
    "    (dfV4['first_down'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Defense Needs a Stop\n",
    "dfV4['def_need_stop'] = (\n",
    "    (dfV4['down'].isin([3, 4])) & \n",
    "    (abs(dfV4['score_differential']) <= 8) & \n",
    "    (dfV4['qtr'] >= 4) &\n",
    "    (dfV4['turnover'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Drought Ending score\n",
    "dfV4['drought_end_play'] = (\n",
    "    ((dfV4['away_csum_scores'].shift(1) >= 2) & (dfV4['away_csum_scores'] == 0) & (dfV4['home_scoring_events'] == 1)) |\n",
    "    ((dfV4['home_csum_scores'].shift(1) >= 2) & (dfV4['home_csum_scores'] == 0) & (dfV4['away_scoring_events'] == 1))\n",
    ").astype(int)\n",
    "\n",
    "# Defensive touchdown\n",
    "dfV4['def_td'] = (\n",
    "    ((dfV4['fumble'] == 1) & (dfV4['return_touchdown'] == 1)) |\n",
    "    ((dfV4['interception'] == 1) & (dfV4['return_touchdown'] == 1))\n",
    ").astype(int)\n",
    "\n",
    "# Defensive touchdown\n",
    "dfV4['off_td'] = (\n",
    "    (dfV4['pass_touchdown'] == 1) | (dfV4['rush_touchdown'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Special Teams touchdown\n",
    "dfV4['st_return_td'] = (\n",
    "    ((dfV4['kickoff_attempt'] == 1) & (dfV4['return_touchdown'] == 1)) | \n",
    "    ((dfV4['punt_attempt'] == 1) & (dfV4['return_touchdown'] == 1))  \n",
    ").astype(int)\n",
    "\n",
    "# Big special teams play...punt blocked, field goal blocked, return_touchdown, kick recovery, pin team near endzone\n",
    "dfV4['big_st_play'] = (\n",
    "    (dfV4['punt_blocked'] == 1) | \n",
    "    (dfV4['field_goal_result'] == 'blocked') | \n",
    "    (dfV4['own_kickoff_recovery'] == 1) | \n",
    "    (dfV4['st_return_td'] == 1) | \n",
    "    (dfV4['kickoff_inside_twenty'] == 1) | \n",
    "    (dfV4['punt_inside_twenty'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Scoring type differentiatior, touchdowns should hold more weight than a field goal, other types may hold more weight also\n",
    "dfV4['scoring_type'] = np.select(\n",
    "    [\n",
    "        dfV4['field_goal_result'] == 'made',\n",
    "        dfV4['off_td'] == 1,\n",
    "        dfV4['def_td'] == 1,\n",
    "        dfV4['st_return_td'] == 1,\n",
    "    ],\n",
    "    ['fg', 'off_td', 'def_td', 'st_td'],\n",
    "    default='none'\n",
    ")\n",
    "\n",
    "# Indicator for big offensive play\n",
    "dfV4['big_offensive_play'] = (\n",
    "        (dfV4['yards_gained'] >= 40) |\n",
    "        (dfV4['long_td'] == 1) |\n",
    "        ((dfV4['off_need_score'] == 1) & (dfV4['off_td'] == 1))\n",
    ").astype(int)\n",
    "\n",
    "# Indicator for big defensive play\n",
    "dfV4['big_defensive_play'] = (\n",
    "    (dfV4['sack'] == 1) |\n",
    "    (dfV4['tackled_for_loss'] == 1) |\n",
    "    ((dfV4['def_need_stop'] == 1) & ((dfV4['def_td'] == 'def_td')) | dfV4['turnover'] == 1) |\n",
    "    (dfV4['scoring_type'] == 'def_td')\n",
    ").astype(int)\n",
    "\n",
    "#Quick Score and Quick Stop #### Needs fixing, only want 1 on last play of drive when they score or get stop, right now 1 for whole drive\n",
    "dfV4['total_drive_time'] = dfV4.groupby('drive')['drive_time_seconds'].transform('last') \n",
    "dfV4['cumulative_drive_time'] = dfV4.groupby(['game_id', 'drive'])['drive_time_seconds'].cumsum()\n",
    "dfV4['long_drive_triggered'] = (\n",
    "    dfV4.groupby(['game_id', 'drive'])['cumulative_drive_time']\n",
    "    .transform(lambda x: (x > 360).idxmax() == x.index)  # Flags the first row that exceeds 360s\n",
    ").astype(int)\n",
    "\n",
    "dfV4['quick_score'] = (\n",
    "    (dfV4['drive_time_seconds'] < 180) &\n",
    "    ((dfV4['touchdown'] == 1) | (dfV4['field_goal_result'] == 'made')) &\n",
    "    (dfV4.groupby('drive')['drive_time_seconds'].transform('last') == dfV4['drive_time_seconds'])\n",
    ").astype(int)\n",
    "dfV4['quick_stop'] = (\n",
    "    (dfV4['total_drive_time'] < 180) & \n",
    "    (dfV4['scoring_type'] == 'none') &\n",
    "    (dfV4.groupby('drive')['drive_time_seconds'].transform('last') == dfV4['drive_time_seconds'])\n",
    ").astype(int)\n",
    "\n",
    "# Consecutive first downs\n",
    "dfV4['home_csum_first_downs'] = 0\n",
    "dfV4['away_csum_first_downs'] = 0\n",
    "dfV4['home_csum_first_downs'] = (\n",
    "    dfV4.groupby(['home_team', 'away_team', 'home_drive_number'])['first_down']\n",
    "    .cumsum()\n",
    "    .where(dfV4['posteam'] != 'away_team', 0)\n",
    ")\n",
    "dfV4['away_csum_first_downs'] = (\n",
    "    dfV4.groupby(['home_team', 'away_team', 'away_drive_number'])['first_down']\n",
    "    .cumsum()\n",
    "    .where(dfV4['posteam'] != 'home_team', 0)\n",
    ")\n",
    "\n",
    "\n",
    "columns_to_remove = [\n",
    "    'ep', 'punt_blocked', 'first_down_rush', 'first_down_pass', \n",
    "    'third_down_converted', 'third_down_failed', 'fourth_down_converted', \n",
    "    'fourth_down_failed', 'incomplete_pass', 'interception', 'fumble_not_forced', \n",
    "    'fumble_out_of_bounds', 'solo_tackle', 'safety', 'penalty', 'tackled_for_loss', \n",
    "    'fumble_lost', 'own_kickoff_recovery', 'own_kickoff_recovery_td', 'qb_hit', \n",
    "    'rush_attempt', 'pass_attempt', 'sack', 'extra_point_attempt', 'two_point_attempt', \n",
    "    'field_goal_attempt', 'kickoff_attempt', 'punt_attempt', 'fumble', 'pass_touchdown', 'rush_touchdown'\n",
    "    'complete_pass', 'shotgun', 'home_scoring_drive', 'away_scoring_drive','home_scoring_events','away_scoring_events',\n",
    "    'rush_touchdown', 'field_goal_result', 'return_touchdown', 'complete_pass', 'no_huddle', 'punt_inside_twenty', 'kickoff_inside_twenty',\n",
    "    'time', 'yrdln', 'ydstogo', 'ydsnet', 'desc', 'side_of_field', 'yardline_100', 'desc', 'drive', 'game_half', 'drive_ended', 'drive_time_seconds',\n",
    "    'touchdown', 'score_differential', 'total_drive_time'\n",
    "]\n",
    "\n",
    "dfV5 = dfV4.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "dynamics = [\n",
    "    ('big_offensive_play', dfV5['big_offensive_play'] == 1),\n",
    "    ('big_defensive_play', dfV5['big_defensive_play'] == 1),\n",
    "    ('off_td', dfV5['off_td'] == 1),\n",
    "    ('def_td', dfV5['def_td'] == 1),\n",
    "    ('big_st_play', dfV5['big_st_play'] == 1),\n",
    "    ('st_return_td', dfV5['st_return_td'] == 1),\n",
    "    ('off_need_score', dfV5['off_need_score'] == 1),\n",
    "    ('def_need_stop', dfV5['def_need_stop'] == 1),\n",
    "    ('drought_end_play', dfV5['drought_end_play'] == 1),\n",
    "    ('home_csum_scores', dfV5['home_csum_scores'] >= 2),\n",
    "    ('away_csum_scores', dfV5['away_csum_scores'] >= 2),\n",
    "    ('home_csum_def_stops', dfV5['home_csum_def_stops'] >= 2),\n",
    "    ('away_csum_def_stops', dfV5['away_csum_def_stops'] >= 2),\n",
    "    ('home_csum_first_downs', dfV5['home_csum_first_downs'] >= 2),\n",
    "    ('away_csum_first_downs', dfV5['away_csum_first_downs'] >= 2),\n",
    "    ('long_td', dfV5['long_td'] == 1),\n",
    "    ('quick_score', dfV5['quick_score'] == 1),\n",
    "    ('quick_stop', dfV5['quick_stop'] == 1),\n",
    "    ('home_score_differential', dfV5['home_score_differential'] == 1),\n",
    "    ('away_score_differential', dfV5['away_score_differential'] == 1),\n",
    "]\n",
    "\n",
    "\n",
    "def_wp_change = {\n",
    "    \"big_defensive_play\": 0.029471,\n",
    "    \"def_td\": 0.016322,\n",
    "    \"big_st_play\": 0.034637,\n",
    "    \"st_return_td\": 0.040082,\n",
    "    \"def_need_stop\": 0.042132,\n",
    "    \"quick_stop\": 0.029971\n",
    "}\n",
    "\n",
    "off_wp_change = {\n",
    "    \"big_offensive_play\": 0.038602,\n",
    "    \"off_td\": 0.028432,\n",
    "    \"off_need_score\":  0.035536, \n",
    "    \"drought_end_play\": 0.028891,\n",
    "    \"long_td\": 0.033325,\n",
    "    \"quick_score\": 0.026664\n",
    "}\n",
    "\n",
    "streaks_multipliers = {\n",
    "    \"home_csum_scores\": 1.118986,\n",
    "    \"away_csum_scores\": 1.118986,\n",
    "    \"home_csum_first_downs\": 1.1112094,\n",
    "    \"away_csum_first_downs\": 1.1112094,\n",
    "    \"home_csum_def_stops\": 1.111932,\n",
    "    \"away_csum_def_stops\": 1.111932,\n",
    "}\n",
    "\n",
    "score_game_multipliers = {\n",
    "    \"tied_or_1_score\": 1.06634844,\n",
    "    \"2_score\": 1.035777727,\n",
    "    \"3_or_more_score\": 1.0274060\n",
    "}\n",
    "\n",
    "qtr_multipliers = {\n",
    "    \"first_and_fourth\": 1.5522285,\n",
    "    \"second_and_third\": 1.3201836\n",
    "}\n",
    "\n",
    "home_away_multipliers = {\n",
    "    \"home\": 1.07949869,  \n",
    "    \"away\": 1.06027507 \n",
    "}\n",
    "\n",
    "boost_case_multipliers = {\n",
    "    \"home_and_4th\": 1.122276683,  \n",
    "    \"away_and_1st\": 1.16675933,  \n",
    "    \"none\": 1.0           \n",
    "}\n",
    "\n",
    "decay_multipliers = {\n",
    "    \"opponent_scores\": 0.68004571,\n",
    "    \"turnover\": 0.21742678,\n",
    "    \"opponent_ends_drought\": 0.18212307,\n",
    "    \"long_possession\":  0.1534018395,\n",
    "    \"none\": 0.0  \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def calculate_multipliers(row, index, category, is_offensive):\n",
    "    if abs(row['home_score_differential']) <= 8:\n",
    "        S = score_game_multipliers[\"tied_or_1_score\"]\n",
    "    elif 9 <= abs(row['home_score_differential']) <= 16:\n",
    "        S = score_game_multipliers[\"2_score\"]\n",
    "    else:\n",
    "        S = score_game_multipliers[\"3_or_more_score\"]\n",
    "\n",
    "    team = row['posteam'] if is_offensive else row['defteam']\n",
    "    HA = home_away_multipliers.get(team, 1.0)\n",
    "\n",
    "    if row['qtr'] == 1 or row['qtr'] == 4:\n",
    "        Q = qtr_multipliers[\"first_and_fourth\"]\n",
    "    else:\n",
    "        Q = qtr_multipliers[\"second_and_third\"]\n",
    "\n",
    "    if is_offensive:\n",
    "        if row['posteam'] == 'home' and row['qtr'] == 4:\n",
    "            B = boost_case_multipliers[\"home_and_4th\"]\n",
    "        elif row['posteam'] == 'away' and row['qtr'] == 1:\n",
    "            B = boost_case_multipliers[\"away_and_1st\"]\n",
    "        else:\n",
    "            B = 1.0\n",
    "    else:\n",
    "        if team == 'home' and row['qtr'] == 4:\n",
    "            B = boost_case_multipliers[\"home_and_4th\"]\n",
    "        elif team == 'away' and row['qtr'] == 1:\n",
    "            B = boost_case_multipliers[\"away_and_1st\"]\n",
    "        else:\n",
    "            B = 1.0\n",
    "\n",
    "    CS = 1.0\n",
    "   \n",
    "    if is_offensive:\n",
    "        if row['posteam'] == row['home_team']:\n",
    "            if row['home_csum_scores'] >= 2:\n",
    "                if row['home_csum_scores'] > dfV5.at[index - 1, 'home_csum_scores']: \n",
    "                    CS = streaks_multipliers['home_csum_scores']\n",
    "            elif row['home_csum_first_downs'] >= 4:\n",
    "                if row['home_csum_first_downs'] > dfV5.at[index - 1, 'home_csum_first_downs']: \n",
    "                    CS = streaks_multipliers['home_csum_first_downs']\n",
    "            else:\n",
    "                CS = 1.0\n",
    "        else:\n",
    "            if row['away_csum_scores'] >= 2:\n",
    "                if row['away_csum_scores'] > dfV5.at[index - 1, 'away_csum_scores']: \n",
    "                    CS = streaks_multipliers['away_csum_scores']\n",
    "            elif row['away_csum_first_downs'] >= 4:\n",
    "                if row['away_csum_first_downs'] >  dfV5.at[index - 1, 'away_csum_first_downs']: \n",
    "                    CS = streaks_multipliers['away_csum_first_downs']\n",
    "            else:\n",
    "                CS = 1.0\n",
    "    else:\n",
    "        if row['defteam'] == row['home_team']:\n",
    "            if row['home_csum_def_stops'] >= 2:\n",
    "                if row['home_csum_def_stops'] > dfV5.at[index - 1, 'home_csum_def_stops']: \n",
    "                    CS = streaks_multipliers['home_csum_def_stops']\n",
    "            else:\n",
    "                CS = 1.0\n",
    "        else:\n",
    "            if row['away_csum_def_stops'] >= 2:\n",
    "                if row['away_csum_def_stops'] > dfV5.at[index - 1, 'away_csum_def_stops']:\n",
    "                    CS = streaks_multipliers['away_csum_def_stops']\n",
    "            else:\n",
    "                CS = 1.0\n",
    "\n",
    "    return S, HA, B, CS, Q\n",
    "\n",
    "\n",
    "\n",
    "def calculate_momentum_gain(wp_change_value, S, HA, CS, B, Q):\n",
    "    return wp_change_value * (S * HA * CS * B * Q) * 1000\n",
    "\n",
    "\n",
    "\n",
    "def calculate_decay(row, category, momentum_gain):\n",
    "    if category in ['off_td', 'long_td', 'def_td', 'st_return_td']:\n",
    "        D = decay_multipliers['opponent_scores']\n",
    "    elif row['turnover'] == 1:\n",
    "        D = decay_multipliers['turnover']\n",
    "    elif row['drought_end_play'] == 1:\n",
    "        D = decay_multipliers[\"opponent_ends_drought\"]\n",
    "    elif row['long_drive_triggered'] == 1:  \n",
    "        D = decay_multipliers['long_possession']\n",
    "    else:\n",
    "        D = decay_multipliers['none']\n",
    "\n",
    "    return momentum_gain * D\n",
    "\n",
    "\n",
    "\n",
    "def update_momentum_scores(dfV5):\n",
    "    dfV5['Home_Momentum_Score'] = 500\n",
    "    dfV5['Away_Momentum_Score'] = 500\n",
    "\n",
    "    dfV5['game_id_diff'] = dfV5['game_id'] != dfV5['game_id'].shift(1)\n",
    "\n",
    "    for index, row in dfV5.iterrows():\n",
    "        if index == 0:  \n",
    "            continue\n",
    "\n",
    "        if row['game_id_diff']:\n",
    "            dfV5.at[index, 'Home_Momentum_Score'] = 500\n",
    "            dfV5.at[index, 'Away_Momentum_Score'] = 500\n",
    "            continue\n",
    "\n",
    "        home_momentum_gain = 0\n",
    "        away_momentum_gain = 0\n",
    "\n",
    "        for category, wp_change_value in off_wp_change.items():\n",
    "            if row[category] == 1:\n",
    "                S, HA, B, CS, Q = calculate_multipliers(row, index, category, True)\n",
    "                momentum_gain = calculate_momentum_gain(wp_change_value, S, HA, CS, B, Q)\n",
    "                momentum_loss = calculate_decay(row, category, momentum_gain)\n",
    "\n",
    "                if row['posteam'] == row['home_team']:\n",
    "                    home_momentum_gain += momentum_gain\n",
    "                    away_momentum_gain -= momentum_loss\n",
    "                else:\n",
    "                    away_momentum_gain += momentum_gain\n",
    "                    home_momentum_gain -= momentum_loss\n",
    "\n",
    "        for category, wp_change_value in def_wp_change.items():\n",
    "            if row[category] == 1:\n",
    "                S, HA, B, CS, Q = calculate_multipliers(row, index, category, False)\n",
    "                momentum_gain = calculate_momentum_gain(wp_change_value, S, HA, CS, B, Q)\n",
    "                momentum_loss = calculate_decay(row, category, momentum_gain)\n",
    "\n",
    "                if row['defteam'] == row['home_team']:\n",
    "                    home_momentum_gain += momentum_gain\n",
    "                    away_momentum_gain -= momentum_loss\n",
    "                else:\n",
    "                    away_momentum_gain += momentum_gain\n",
    "                    home_momentum_gain -= momentum_loss\n",
    "\n",
    "        dfV5.at[index, 'Home_Momentum_Score'] = dfV5.at[index - 1, 'Home_Momentum_Score'] + home_momentum_gain\n",
    "        dfV5.at[index, 'Away_Momentum_Score'] = dfV5.at[index - 1, 'Away_Momentum_Score'] + away_momentum_gain\n",
    "\n",
    "update_momentum_scores(dfV5)\n",
    "\n",
    "dfV5['Game_Momentum_Diff'] = 0\n",
    "\n",
    "historical_max_diff_mean = dfV5.groupby('game_id')['Game_Momentum_Diff'].max().mean()\n",
    "historical_max_diff_std = dfV5.groupby('game_id')['Game_Momentum_Diff'].max().std()\n",
    "\n",
    "base_threshold = historical_max_diff_mean + 0.8 * historical_max_diff_std #.7\n",
    "\n",
    "dfV5['Game_Momentum_Diff'] = abs(dfV5['Home_Momentum_Score'] - dfV5['Away_Momentum_Score'])\n",
    "dfV5['Dynamic_Threshold'] = None\n",
    "dfV5['Momentum_Holding_Team'] = None\n",
    "\n",
    "def detect_momentum_shifts(game_data):\n",
    "    momentum_holding_team = None\n",
    "    last_shift_home_momentum = game_data.iloc[0]['Home_Momentum_Score']\n",
    "    last_shift_away_momentum = game_data.iloc[0]['Away_Momentum_Score']\n",
    "    max_momentum_diff_so_far = 0\n",
    "\n",
    "    for i in range(1, len(game_data)): \n",
    "        if i < 10:  # Ignore shifts for the first 10 plays\n",
    "            continue\n",
    "        home_momentum_diff = game_data.iloc[i]['Home_Momentum_Score'] - last_shift_home_momentum\n",
    "        away_momentum_diff = game_data.iloc[i]['Away_Momentum_Score'] - last_shift_away_momentum        \n",
    "\n",
    "        current_momentum_diff = abs(game_data.iloc[i]['Home_Momentum_Score'] - game_data.iloc[i]['Away_Momentum_Score'])\n",
    "        max_momentum_diff_so_far = max(max_momentum_diff_so_far, current_momentum_diff)\n",
    "        game_threshold = max(base_threshold, 0.8 * max_momentum_diff_so_far) #.7\n",
    "        game_data.iloc[i, game_data.columns.get_loc('Dynamic_Threshold')] = game_threshold\n",
    "\n",
    "        home_momentum_shift = False\n",
    "        away_momentum_shift = False\n",
    "\n",
    "        if home_momentum_diff >= game_threshold and away_momentum_diff < game_threshold * 0.8: #.5\n",
    "            home_momentum_shift = True\n",
    "        elif away_momentum_diff >= game_threshold and home_momentum_diff < game_threshold * 0.8: #.5\n",
    "            away_momentum_shift = True\n",
    "\n",
    "        if home_momentum_shift:\n",
    "            momentum_holding_team = \"Home\"\n",
    "            last_shift_home_momentum = game_data.iloc[i]['Home_Momentum_Score']\n",
    "            last_shift_away_momentum = game_data.iloc[i]['Away_Momentum_Score']\n",
    "        elif away_momentum_shift:\n",
    "            momentum_holding_team = \"Away\"\n",
    "            last_shift_home_momentum = game_data.iloc[i]['Home_Momentum_Score']\n",
    "            last_shift_away_momentum = game_data.iloc[i]['Away_Momentum_Score']\n",
    "\n",
    "        game_data.iloc[i, game_data.columns.get_loc('Momentum_Holding_Team')] = momentum_holding_team\n",
    "\n",
    "    return game_data\n",
    "\n",
    "dfV5 = dfV5.groupby('game_id', group_keys=False).apply(detect_momentum_shifts)\n",
    "\n",
    "dfV5['Momentum_Shift_Occurred'] = dfV5.groupby('game_id')['Momentum_Holding_Team'].transform(\n",
    "    lambda x: x.ne(x.shift()) & x.notna()\n",
    ")\n",
    "\n",
    "columns_to_fill = ['home_drive_number', 'away_drive_number', 'home_csum_first_downs', \n",
    "                    'away_csum_first_downs', 'Dynamic_Threshold', 'yards_gained']\n",
    "dfV5[columns_to_fill] = dfV5[columns_to_fill].fillna(0)\n",
    "\n",
    "features = dfV5.drop(['Momentum_Shift_Occurred'], axis=1)  \n",
    "numeric_df = dfV5.select_dtypes(include=[np.number])\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(numeric_df)\n",
    "\n",
    "pca = PCA(n_components=0.90)\n",
    "principal_components = pca.fit_transform(scaled_data)\n",
    "\n",
    "pca_df = pd.DataFrame(principal_components, columns=[f'PC{i+1}' for i in range(pca.n_components_)])\n",
    "pca_df['Momentum_Shift_Occurred'] = dfV5['Momentum_Shift_Occurred'].values\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best Parameters: {'alpha': 0.001, 'hidden_layer_sizes': (32, 16), 'max_iter': 500, 'solver': 'adam'}\n",
      "Best Cross-Validation F1 Score: 0.26989819607297105\n",
      "Best threshold: 0.16842105263157897, Best F1: 0.3224\n",
      "\n",
      "=== Train Set ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    331300\n",
      "           1       0.46      0.77      0.57      6975\n",
      "\n",
      "    accuracy                           0.98    338275\n",
      "   macro avg       0.73      0.87      0.78    338275\n",
      "weighted avg       0.98      0.98      0.98    338275\n",
      "\n",
      "=== Test Set ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     82061\n",
      "           1       0.26      0.42      0.32      1726\n",
      "\n",
      "    accuracy                           0.96     83787\n",
      "   macro avg       0.62      0.70      0.65     83787\n",
      "weighted avg       0.97      0.96      0.97     83787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "df = dfV5.copy()\n",
    "\n",
    "excluded_cols = ['game_id', 'Momentum_Shift_Occurred', 'Momentum_Holding_Team']\n",
    "target_col = 'Momentum_Shift_Occurred'\n",
    "feature_df = df.drop(columns=excluded_cols, errors='ignore')\n",
    "\n",
    "numeric_cols = feature_df.select_dtypes(include=['number']).columns\n",
    "categorical_cols = feature_df.select_dtypes(exclude=['number']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    feature_df = pd.get_dummies(feature_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "unique_games = df['game_id'].unique()\n",
    "unique_games_sorted = sorted(unique_games)\n",
    "train_size = int(0.8 * len(unique_games_sorted))\n",
    "train_games = unique_games_sorted[:train_size]\n",
    "test_games = unique_games_sorted[train_size:]\n",
    "\n",
    "feature_df['game_id'] = df['game_id']\n",
    "train_features = feature_df[feature_df['game_id'].isin(train_games)].drop(columns='game_id')\n",
    "test_features = feature_df[feature_df['game_id'].isin(test_games)].drop(columns='game_id')\n",
    "X_train = train_features.values\n",
    "X_test = test_features.values\n",
    "y_train = df.loc[df['game_id'].isin(train_games), target_col].astype(int).values\n",
    "y_test = df.loc[df['game_id'].isin(test_games), target_col].astype(int).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Hyperparameter Tuning for Class 1 Optimization\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(32, 16), (64, 32, 16), (128, 64, 32)],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'solver': ['adam'],\n",
    "    'max_iter': [500, 1000]\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(mlp, param_grid, scoring=f1_scorer, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation F1 Score:\", grid_search.best_score_)\n",
    "\n",
    "# Threshold Tuning After Training\n",
    "y_test_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "best_threshold, best_f1 = 0.5, 0\n",
    "for t in np.linspace(0.05, 0.5, 20):\n",
    "    y_pred_t = (y_test_proba >= t).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred_t)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"Best threshold: {best_threshold}, Best F1: {best_f1:.4f}\")\n",
    "\n",
    "# Final Evaluation\n",
    "y_train_pred = (best_model.predict_proba(X_train_scaled)[:, 1] >= best_threshold).astype(int)\n",
    "y_test_pred = (y_test_proba >= best_threshold).astype(int)\n",
    "\n",
    "print(\"\\n=== Train Set ===\")\n",
    "print(classification_report(y_train, y_train_pred, zero_division=0))\n",
    "\n",
    "print(\"=== Test Set ===\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Train Set with 6-Play Tolerance (Threshold Applied) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94    298549\n",
      "           1       0.55      0.78      0.65     39726\n",
      "\n",
      "    accuracy                           0.90    338275\n",
      "   macro avg       0.76      0.85      0.79    338275\n",
      "weighted avg       0.92      0.90      0.91    338275\n",
      "\n",
      "\n",
      "=== Test Set with 6-Play Tolerance (Threshold Applied) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     73947\n",
      "           1       0.38      0.52      0.44      9840\n",
      "\n",
      "    accuracy                           0.85     83787\n",
      "   macro avg       0.66      0.71      0.68     83787\n",
      "weighted avg       0.87      0.85      0.86     83787\n",
      "\n",
      "\n",
      "=== Train Set with 6-Play Tolerance (No Threshold Applied) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96    298549\n",
      "           1       0.85      0.44      0.58     39726\n",
      "\n",
      "    accuracy                           0.92    338275\n",
      "   macro avg       0.89      0.71      0.77    338275\n",
      "weighted avg       0.92      0.92      0.91    338275\n",
      "\n",
      "\n",
      "=== Test Set with 6-Play Tolerance (No Threshold Applied) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94     73947\n",
      "           1       0.50      0.25      0.34      9840\n",
      "\n",
      "    accuracy                           0.88     83787\n",
      "   macro avg       0.71      0.61      0.64     83787\n",
      "weighted avg       0.86      0.88      0.87     83787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import maximum_filter1d\n",
    "\n",
    "df = dfV5.copy()\n",
    "\n",
    "excluded_cols = ['game_id', 'Momentum_Shift_Occurred', 'Momentum_Holding_Team']\n",
    "target_col = 'Momentum_Shift_Occurred'\n",
    "feature_df = df.drop(columns=excluded_cols, errors='ignore')\n",
    "\n",
    "numeric_cols = feature_df.select_dtypes(include=['number']).columns\n",
    "categorical_cols = feature_df.select_dtypes(exclude=['number']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    feature_df = pd.get_dummies(feature_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "unique_games = df['game_id'].unique()\n",
    "unique_games_sorted = sorted(unique_games)\n",
    "train_size = int(0.8 * len(unique_games_sorted))\n",
    "train_games = unique_games_sorted[:train_size]\n",
    "test_games = unique_games_sorted[train_size:]\n",
    "\n",
    "feature_df['game_id'] = df['game_id']\n",
    "train_features = feature_df[feature_df['game_id'].isin(train_games)].drop(columns='game_id')\n",
    "test_features = feature_df[feature_df['game_id'].isin(test_games)].drop(columns='game_id')\n",
    "X_train = train_features.values\n",
    "X_test = test_features.values\n",
    "y_train = df.loc[df['game_id'].isin(train_games), target_col].astype(int).values\n",
    "y_test = df.loc[df['game_id'].isin(test_games), target_col].astype(int).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(32, 16), alpha=0.001, solver='adam', max_iter=500, random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict Probabilities\n",
    "y_train_proba = mlp.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_proba = mlp.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Apply Best Threshold for Predictions\n",
    "y_train_pred_threshold = (y_train_proba >= 0.16842105263157897).astype(int)\n",
    "y_test_pred_threshold = (y_test_proba >= 0.16842105263157897).astype(int)\n",
    "\n",
    "# Apply Temporal Tolerance (6-Play Window)\n",
    "y_train_tolerant = maximum_filter1d(y_train, size=6, mode='constant', cval=0)\n",
    "y_train_pred_tolerant = maximum_filter1d(y_train_pred_threshold, size=6, mode='constant', cval=0)\n",
    "y_test_tolerant = maximum_filter1d(y_test, size=6, mode='constant', cval=0)\n",
    "y_test_pred_tolerant = maximum_filter1d(y_test_pred_threshold, size=6, mode='constant', cval=0)\n",
    "\n",
    "# Evaluate with Best Threshold\n",
    "print(\"\\n=== Train Set with 6-Play Tolerance (Threshold Applied) ===\")\n",
    "print(classification_report(y_train_tolerant, y_train_pred_tolerant, zero_division=0))\n",
    "print(\"\\n=== Test Set with 6-Play Tolerance (Threshold Applied) ===\")\n",
    "print(classification_report(y_test_tolerant, y_test_pred_tolerant, zero_division=0))\n",
    "\n",
    "# Evaluate Without Applying Threshold\n",
    "y_train_pred_no_threshold = (y_train_proba >= 0.5).astype(int)\n",
    "y_test_pred_no_threshold = (y_test_proba >= 0.5).astype(int)\n",
    "\n",
    "y_train_pred_no_threshold_tolerant = maximum_filter1d(y_train_pred_no_threshold, size=6, mode='constant', cval=0)\n",
    "y_test_pred_no_threshold_tolerant = maximum_filter1d(y_test_pred_no_threshold, size=6, mode='constant', cval=0)\n",
    "\n",
    "print(\"\\n=== Train Set with 6-Play Tolerance (No Threshold Applied) ===\")\n",
    "print(classification_report(y_train_tolerant, y_train_pred_no_threshold_tolerant, zero_division=0))\n",
    "print(\"\\n=== Test Set with 6-Play Tolerance (No Threshold Applied) ===\")\n",
    "print(classification_report(y_test_tolerant, y_test_pred_no_threshold_tolerant, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Train Set with 6-Play Tolerance (Threshold Applied) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.28      0.43    298549\n",
      "           1       0.16      1.00      0.27     39726\n",
      "\n",
      "    accuracy                           0.36    338275\n",
      "   macro avg       0.58      0.64      0.35    338275\n",
      "weighted avg       0.90      0.36      0.41    338275\n",
      "\n",
      "\n",
      "=== Test Set with 6-Play Tolerance (Threshold Applied) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.27      0.43     73947\n",
      "           1       0.15      0.99      0.27      9840\n",
      "\n",
      "    accuracy                           0.36     83787\n",
      "   macro avg       0.58      0.63      0.35     83787\n",
      "weighted avg       0.90      0.36      0.41     83787\n",
      "\n",
      "\n",
      "=== Train Set with 6-Play Tolerance (No Threshold Applied) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.52      0.69    298549\n",
      "           1       0.22      0.99      0.36     39726\n",
      "\n",
      "    accuracy                           0.58    338275\n",
      "   macro avg       0.61      0.76      0.52    338275\n",
      "weighted avg       0.91      0.58      0.65    338275\n",
      "\n",
      "\n",
      "=== Test Set with 6-Play Tolerance (No Threshold Applied) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.52      0.68     73947\n",
      "           1       0.20      0.92      0.33      9840\n",
      "\n",
      "    accuracy                           0.56     83787\n",
      "   macro avg       0.59      0.72      0.50     83787\n",
      "weighted avg       0.89      0.56      0.64     83787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "balanced_mlp = BalancedBaggingClassifier(\n",
    "    estimator=mlp,\n",
    "    n_estimators=10,  # Number of models to ensemble\n",
    "    sampling_strategy=0.8,  # Adjust how much balancing occurs\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "balanced_mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_proba = balanced_mlp.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_proba = balanced_mlp.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Apply Best Threshold for Predictions\n",
    "y_train_pred_threshold = (y_train_proba >= 0.16842105263157897).astype(int)\n",
    "y_test_pred_threshold = (y_test_proba >= 0.16842105263157897).astype(int)\n",
    "\n",
    "# Apply Temporal Tolerance (6-Play Window)\n",
    "y_train_tolerant = maximum_filter1d(y_train, size=6, mode='constant', cval=0)\n",
    "y_train_pred_tolerant = maximum_filter1d(y_train_pred_threshold, size=6, mode='constant', cval=0)\n",
    "y_test_tolerant = maximum_filter1d(y_test, size=6, mode='constant', cval=0)\n",
    "y_test_pred_tolerant = maximum_filter1d(y_test_pred_threshold, size=6, mode='constant', cval=0)\n",
    "\n",
    "# Evaluate with Best Threshold\n",
    "print(\"\\n=== Train Set with 6-Play Tolerance (Threshold Applied) ===\")\n",
    "print(classification_report(y_train_tolerant, y_train_pred_tolerant, zero_division=0))\n",
    "print(\"\\n=== Test Set with 6-Play Tolerance (Threshold Applied) ===\")\n",
    "print(classification_report(y_test_tolerant, y_test_pred_tolerant, zero_division=0))\n",
    "\n",
    "# Evaluate Without Applying Threshold\n",
    "y_train_pred_no_threshold = (y_train_proba >= 0.5).astype(int)\n",
    "y_test_pred_no_threshold = (y_test_proba >= 0.5).astype(int)\n",
    "\n",
    "y_train_pred_no_threshold_tolerant = maximum_filter1d(y_train_pred_no_threshold, size=6, mode='constant', cval=0)\n",
    "y_test_pred_no_threshold_tolerant = maximum_filter1d(y_test_pred_no_threshold, size=6, mode='constant', cval=0)\n",
    "\n",
    "print(\"\\n=== Train Set with 6-Play Tolerance (No Threshold Applied) ===\")\n",
    "print(classification_report(y_train_tolerant, y_train_pred_no_threshold_tolerant, zero_division=0))\n",
    "print(\"\\n=== Test Set with 6-Play Tolerance (No Threshold Applied) ===\")\n",
    "print(classification_report(y_test_tolerant, y_test_pred_no_threshold_tolerant, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed:\n",
    "\n",
    "Did look at ensemble, was thinking of trying combined ensemble?????\n",
    "Minor Undersampling -? method that does ?\n",
    "Hypertuned Parameters with extra parameter that was missing and bigger network\n",
    "Hypertuned prediction threshold to help raise f1 score if possible\n",
    "Trained model with parameters + prediction threshold resulting in highest f1 score for class 1, and itroduced 6 play ?fault tolerance?\n",
    "Trained model with parameters(No Threshold) resulting in highest f1 score for class 1, and itroduced 6 play ?fault tolerance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
